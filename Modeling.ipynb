{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 300)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/california_wildfires.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>county</th>\n",
       "      <th>year</th>\n",
       "      <th>acres_burned</th>\n",
       "      <th>fire_started</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Alfalfa &amp; Hay_acres</th>\n",
       "      <th>Alfalfa &amp; Hay_percentage</th>\n",
       "      <th>Almonds_acres</th>\n",
       "      <th>Almonds_percentage</th>\n",
       "      <th>Barren_acres</th>\n",
       "      <th>Barren_percentage</th>\n",
       "      <th>Corn_acres</th>\n",
       "      <th>Corn_percentage</th>\n",
       "      <th>Cotton_acres</th>\n",
       "      <th>Cotton_percentage</th>\n",
       "      <th>Deciduous Forest_acres</th>\n",
       "      <th>Deciduous Forest_percentage</th>\n",
       "      <th>Evergreen Forest_acres</th>\n",
       "      <th>Evergreen Forest_percentage</th>\n",
       "      <th>Fallow_acres</th>\n",
       "      <th>Fallow_percentage</th>\n",
       "      <th>Fruit Trees_acres</th>\n",
       "      <th>Fruit Trees_percentage</th>\n",
       "      <th>Grain Crops_acres</th>\n",
       "      <th>Grain Crops_percentage</th>\n",
       "      <th>Grapes_acres</th>\n",
       "      <th>Grapes_percentage</th>\n",
       "      <th>Grassland_acres</th>\n",
       "      <th>Grassland_percentage</th>\n",
       "      <th>High Intensity Developed_acres</th>\n",
       "      <th>High Intensity Developed_percentage</th>\n",
       "      <th>Low Intensity Developed_acres</th>\n",
       "      <th>Low Intensity Developed_percentage</th>\n",
       "      <th>Mixed Forest_acres</th>\n",
       "      <th>Mixed Forest_percentage</th>\n",
       "      <th>Other Ocean/Mexico_acres</th>\n",
       "      <th>Other Ocean/Mexico_percentage</th>\n",
       "      <th>Other Tree Crops_acres</th>\n",
       "      <th>Other Tree Crops_percentage</th>\n",
       "      <th>Other_acres</th>\n",
       "      <th>Other_percentage</th>\n",
       "      <th>Rice_acres</th>\n",
       "      <th>Rice_percentage</th>\n",
       "      <th>Shrubland_acres</th>\n",
       "      <th>Shrubland_percentage</th>\n",
       "      <th>Tomatoes_acres</th>\n",
       "      <th>Tomatoes_percentage</th>\n",
       "      <th>Vegs &amp; Fruits_acres</th>\n",
       "      <th>Vegs &amp; Fruits_percentage</th>\n",
       "      <th>Walnuts_acres</th>\n",
       "      <th>Walnuts_percentage</th>\n",
       "      <th>Water_acres</th>\n",
       "      <th>Water_percentage</th>\n",
       "      <th>Wetlands_acres</th>\n",
       "      <th>Wetlands_percentage</th>\n",
       "      <th>Winter Wheat_acres</th>\n",
       "      <th>Winter Wheat_percentage</th>\n",
       "      <th>max_elevation</th>\n",
       "      <th>min_elevation</th>\n",
       "      <th>Avg Air Temp (F)_Weekly</th>\n",
       "      <th>Avg Rel Hum (%)_Weekly</th>\n",
       "      <th>Avg Wind Speed (mph)_Weekly</th>\n",
       "      <th>Dew Point (F)_Weekly</th>\n",
       "      <th>Max Air Temp (F)_Weekly</th>\n",
       "      <th>Max Rel Hum (%)_Weekly</th>\n",
       "      <th>Min Air Temp (F)_Weekly</th>\n",
       "      <th>Min Rel Hum (%)_Weekly</th>\n",
       "      <th>Precip (in)_Weekly</th>\n",
       "      <th>Avg Air Temp (F)_month</th>\n",
       "      <th>Avg Rel Hum (%)_month</th>\n",
       "      <th>Avg Wind Speed (mph)_month</th>\n",
       "      <th>Dew Point (F)_month</th>\n",
       "      <th>Max Air Temp (F)_month</th>\n",
       "      <th>Max Rel Hum (%)_month</th>\n",
       "      <th>Min Air Temp (F)_month</th>\n",
       "      <th>Min Rel Hum (%)_month</th>\n",
       "      <th>Precip (in)_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1102.856805</td>\n",
       "      <td>0.300074</td>\n",
       "      <td>4.225505</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>194.595625</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>4.670295</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.337480</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>7838.756565</td>\n",
       "      <td>2.132827</td>\n",
       "      <td>1536.749450</td>\n",
       "      <td>0.418130</td>\n",
       "      <td>1.779160</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>991.214515</td>\n",
       "      <td>0.269697</td>\n",
       "      <td>3722.447510</td>\n",
       "      <td>1.012831</td>\n",
       "      <td>153671.386680</td>\n",
       "      <td>41.812059</td>\n",
       "      <td>28431.421590</td>\n",
       "      <td>7.735834</td>\n",
       "      <td>39470.886995</td>\n",
       "      <td>10.739534</td>\n",
       "      <td>74885.956375</td>\n",
       "      <td>20.375531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.673405</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889580</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>30958.051185</td>\n",
       "      <td>8.423298</td>\n",
       "      <td>4.670295</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>164.127510</td>\n",
       "      <td>0.044657</td>\n",
       "      <td>4.670295</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>19403.518960</td>\n",
       "      <td>5.279454</td>\n",
       "      <td>4497.494085</td>\n",
       "      <td>1.223712</td>\n",
       "      <td>624.485160</td>\n",
       "      <td>0.169915</td>\n",
       "      <td>1242</td>\n",
       "      <td>-42</td>\n",
       "      <td>44.214286</td>\n",
       "      <td>82.785714</td>\n",
       "      <td>2.392857</td>\n",
       "      <td>39.321429</td>\n",
       "      <td>54.157143</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>35.771429</td>\n",
       "      <td>60.785714</td>\n",
       "      <td>0.095714</td>\n",
       "      <td>45.506897</td>\n",
       "      <td>78.189655</td>\n",
       "      <td>2.915517</td>\n",
       "      <td>38.932759</td>\n",
       "      <td>55.896552</td>\n",
       "      <td>95.448276</td>\n",
       "      <td>35.725862</td>\n",
       "      <td>55.810345</td>\n",
       "      <td>0.130172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>Alpine</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>189.035750</td>\n",
       "      <td>0.040080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15482.472715</td>\n",
       "      <td>3.282650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>194.595625</td>\n",
       "      <td>0.041259</td>\n",
       "      <td>195088.007530</td>\n",
       "      <td>41.363269</td>\n",
       "      <td>0.444790</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.222395</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5644.829890</td>\n",
       "      <td>1.196837</td>\n",
       "      <td>121.427670</td>\n",
       "      <td>0.025746</td>\n",
       "      <td>3192.480225</td>\n",
       "      <td>0.676881</td>\n",
       "      <td>0.667185</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>247783.390805</td>\n",
       "      <td>52.535935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2650.503610</td>\n",
       "      <td>0.561969</td>\n",
       "      <td>1297.452430</td>\n",
       "      <td>0.275091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3556</td>\n",
       "      <td>1442</td>\n",
       "      <td>29.657143</td>\n",
       "      <td>76.514286</td>\n",
       "      <td>3.228571</td>\n",
       "      <td>21.328571</td>\n",
       "      <td>34.428571</td>\n",
       "      <td>91.857143</td>\n",
       "      <td>22.857143</td>\n",
       "      <td>55.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.789655</td>\n",
       "      <td>68.162069</td>\n",
       "      <td>4.968966</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>39.344828</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>22.758621</td>\n",
       "      <td>46.344828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>Amador</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1326.808570</td>\n",
       "      <td>0.414290</td>\n",
       "      <td>16.679625</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>1873.010690</td>\n",
       "      <td>0.584840</td>\n",
       "      <td>242.632945</td>\n",
       "      <td>0.075761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17190.911105</td>\n",
       "      <td>5.367789</td>\n",
       "      <td>114386.866695</td>\n",
       "      <td>35.716810</td>\n",
       "      <td>168.130620</td>\n",
       "      <td>0.052498</td>\n",
       "      <td>12.009330</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>120.093300</td>\n",
       "      <td>0.037499</td>\n",
       "      <td>2587.343430</td>\n",
       "      <td>0.807887</td>\n",
       "      <td>112912.610240</td>\n",
       "      <td>35.256480</td>\n",
       "      <td>440.119705</td>\n",
       "      <td>0.137425</td>\n",
       "      <td>8263.975805</td>\n",
       "      <td>2.580391</td>\n",
       "      <td>1727.119570</td>\n",
       "      <td>0.539286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.334370</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111975</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>52457.865415</td>\n",
       "      <td>16.379744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.779160</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>122.094855</td>\n",
       "      <td>0.038124</td>\n",
       "      <td>5822.745890</td>\n",
       "      <td>1.818128</td>\n",
       "      <td>105.860020</td>\n",
       "      <td>0.033054</td>\n",
       "      <td>479.483620</td>\n",
       "      <td>0.149717</td>\n",
       "      <td>3121</td>\n",
       "      <td>43</td>\n",
       "      <td>34.114286</td>\n",
       "      <td>83.571429</td>\n",
       "      <td>3.157143</td>\n",
       "      <td>29.585714</td>\n",
       "      <td>40.071429</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>27.757143</td>\n",
       "      <td>66.571429</td>\n",
       "      <td>0.141429</td>\n",
       "      <td>34.289655</td>\n",
       "      <td>76.724138</td>\n",
       "      <td>3.606897</td>\n",
       "      <td>27.410345</td>\n",
       "      <td>41.200000</td>\n",
       "      <td>93.172414</td>\n",
       "      <td>27.768966</td>\n",
       "      <td>58.310345</td>\n",
       "      <td>0.155517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>Butte</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3777.156680</td>\n",
       "      <td>0.374865</td>\n",
       "      <td>46196.556585</td>\n",
       "      <td>4.584787</td>\n",
       "      <td>1869.452370</td>\n",
       "      <td>0.185534</td>\n",
       "      <td>2023.349710</td>\n",
       "      <td>0.200808</td>\n",
       "      <td>9.118195</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>33181.556395</td>\n",
       "      <td>3.293111</td>\n",
       "      <td>408193.790775</td>\n",
       "      <td>40.511281</td>\n",
       "      <td>56434.510410</td>\n",
       "      <td>5.600855</td>\n",
       "      <td>10563.317710</td>\n",
       "      <td>1.048359</td>\n",
       "      <td>2628.041715</td>\n",
       "      <td>0.260821</td>\n",
       "      <td>247.525635</td>\n",
       "      <td>0.024566</td>\n",
       "      <td>170758.216925</td>\n",
       "      <td>16.946936</td>\n",
       "      <td>4421.657390</td>\n",
       "      <td>0.438828</td>\n",
       "      <td>25520.048645</td>\n",
       "      <td>2.532743</td>\n",
       "      <td>165.684275</td>\n",
       "      <td>0.016443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>790.391830</td>\n",
       "      <td>0.078443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105624.281300</td>\n",
       "      <td>10.482705</td>\n",
       "      <td>55372.129495</td>\n",
       "      <td>5.495419</td>\n",
       "      <td>94.295480</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>469.475845</td>\n",
       "      <td>0.046593</td>\n",
       "      <td>42057.340845</td>\n",
       "      <td>4.173990</td>\n",
       "      <td>21360.372565</td>\n",
       "      <td>2.119915</td>\n",
       "      <td>11589.893030</td>\n",
       "      <td>1.150241</td>\n",
       "      <td>4257.085090</td>\n",
       "      <td>0.422495</td>\n",
       "      <td>2192</td>\n",
       "      <td>-1</td>\n",
       "      <td>40.985714</td>\n",
       "      <td>81.285714</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>35.557143</td>\n",
       "      <td>50.114286</td>\n",
       "      <td>91.285714</td>\n",
       "      <td>32.171429</td>\n",
       "      <td>62.857143</td>\n",
       "      <td>0.117143</td>\n",
       "      <td>42.389655</td>\n",
       "      <td>77.448276</td>\n",
       "      <td>3.848276</td>\n",
       "      <td>35.586207</td>\n",
       "      <td>52.455172</td>\n",
       "      <td>88.965517</td>\n",
       "      <td>33.365517</td>\n",
       "      <td>58.862069</td>\n",
       "      <td>0.175517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>Calaveras</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>31.802485</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>28.466560</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>218.391890</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.889580</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34882.878145</td>\n",
       "      <td>5.495994</td>\n",
       "      <td>255438.004310</td>\n",
       "      <td>40.245698</td>\n",
       "      <td>28.688955</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>12.231725</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>2.223950</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>522.183460</td>\n",
       "      <td>0.082273</td>\n",
       "      <td>207502.763615</td>\n",
       "      <td>32.693230</td>\n",
       "      <td>465.027945</td>\n",
       "      <td>0.073268</td>\n",
       "      <td>12257.745215</td>\n",
       "      <td>1.931277</td>\n",
       "      <td>3351.270255</td>\n",
       "      <td>0.528012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889580</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106091.088405</td>\n",
       "      <td>16.715249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667185</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>425.664030</td>\n",
       "      <td>0.067066</td>\n",
       "      <td>13178.682910</td>\n",
       "      <td>2.076376</td>\n",
       "      <td>245.079290</td>\n",
       "      <td>0.038614</td>\n",
       "      <td>11.786935</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>3522</td>\n",
       "      <td>787</td>\n",
       "      <td>41.928571</td>\n",
       "      <td>93.014286</td>\n",
       "      <td>5.657143</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>50.142857</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.571429</td>\n",
       "      <td>74.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.931034</td>\n",
       "      <td>87.017241</td>\n",
       "      <td>6.268966</td>\n",
       "      <td>37.196552</td>\n",
       "      <td>52.827586</td>\n",
       "      <td>97.551724</td>\n",
       "      <td>34.344828</td>\n",
       "      <td>61.275862</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date     county  year  acres_burned  fire_started  \\\n",
       "0           0  2013-01-06    Alameda  2013           0.0           0.0   \n",
       "1           1  2013-01-06     Alpine  2013           0.0           0.0   \n",
       "2           2  2013-01-06     Amador  2013           0.0           0.0   \n",
       "3           3  2013-01-06      Butte  2013           0.0           0.0   \n",
       "4           4  2013-01-06  Calaveras  2013           0.0           0.0   \n",
       "\n",
       "   Unnamed: 0.1  Alfalfa & Hay_acres  Alfalfa & Hay_percentage  Almonds_acres  \\\n",
       "0             2          1102.856805                  0.300074       4.225505   \n",
       "1             2           189.035750                  0.040080       0.000000   \n",
       "2             2          1326.808570                  0.414290      16.679625   \n",
       "3             2          3777.156680                  0.374865   46196.556585   \n",
       "4             2            31.802485                  0.005011      28.466560   \n",
       "\n",
       "   Almonds_percentage  Barren_acres  Barren_percentage   Corn_acres  \\\n",
       "0            0.001150    194.595625           0.052947     4.670295   \n",
       "1            0.000000  15482.472715           3.282650     0.000000   \n",
       "2            0.005208   1873.010690           0.584840   242.632945   \n",
       "3            4.584787   1869.452370           0.185534  2023.349710   \n",
       "4            0.004485    218.391890           0.034409     0.889580   \n",
       "\n",
       "   Corn_percentage  Cotton_acres  Cotton_percentage  Deciduous Forest_acres  \\\n",
       "0         0.001271      0.000000           0.000000                5.337480   \n",
       "1         0.000000      0.000000           0.000000              194.595625   \n",
       "2         0.075761      0.000000           0.000000            17190.911105   \n",
       "3         0.200808      9.118195           0.000905            33181.556395   \n",
       "4         0.000140      0.000000           0.000000            34882.878145   \n",
       "\n",
       "   Deciduous Forest_percentage  Evergreen Forest_acres  \\\n",
       "0                     0.001452             7838.756565   \n",
       "1                     0.041259           195088.007530   \n",
       "2                     5.367789           114386.866695   \n",
       "3                     3.293111           408193.790775   \n",
       "4                     5.495994           255438.004310   \n",
       "\n",
       "   Evergreen Forest_percentage  Fallow_acres  Fallow_percentage  \\\n",
       "0                     2.132827   1536.749450           0.418130   \n",
       "1                    41.363269      0.444790           0.000094   \n",
       "2                    35.716810    168.130620           0.052498   \n",
       "3                    40.511281  56434.510410           5.600855   \n",
       "4                    40.245698     28.688955           0.004520   \n",
       "\n",
       "   Fruit Trees_acres  Fruit Trees_percentage  Grain Crops_acres  \\\n",
       "0           1.779160                0.000484         991.214515   \n",
       "1           0.222395                0.000047           0.000000   \n",
       "2          12.009330                0.003750         120.093300   \n",
       "3       10563.317710                1.048359        2628.041715   \n",
       "4          12.231725                0.001927           2.223950   \n",
       "\n",
       "   Grain Crops_percentage  Grapes_acres  Grapes_percentage  Grassland_acres  \\\n",
       "0                0.269697   3722.447510           1.012831    153671.386680   \n",
       "1                0.000000      0.000000           0.000000      5644.829890   \n",
       "2                0.037499   2587.343430           0.807887    112912.610240   \n",
       "3                0.260821    247.525635           0.024566    170758.216925   \n",
       "4                0.000350    522.183460           0.082273    207502.763615   \n",
       "\n",
       "   Grassland_percentage  High Intensity Developed_acres  \\\n",
       "0             41.812059                    28431.421590   \n",
       "1              1.196837                      121.427670   \n",
       "2             35.256480                      440.119705   \n",
       "3             16.946936                     4421.657390   \n",
       "4             32.693230                      465.027945   \n",
       "\n",
       "   High Intensity Developed_percentage  Low Intensity Developed_acres  \\\n",
       "0                             7.735834                   39470.886995   \n",
       "1                             0.025746                    3192.480225   \n",
       "2                             0.137425                    8263.975805   \n",
       "3                             0.438828                   25520.048645   \n",
       "4                             0.073268                   12257.745215   \n",
       "\n",
       "   Low Intensity Developed_percentage  Mixed Forest_acres  \\\n",
       "0                           10.739534        74885.956375   \n",
       "1                            0.676881            0.667185   \n",
       "2                            2.580391         1727.119570   \n",
       "3                            2.532743          165.684275   \n",
       "4                            1.931277         3351.270255   \n",
       "\n",
       "   Mixed Forest_percentage  Other Ocean/Mexico_acres  \\\n",
       "0                20.375531                       0.0   \n",
       "1                 0.000141                       0.0   \n",
       "2                 0.539286                       0.0   \n",
       "3                 0.016443                       0.0   \n",
       "4                 0.528012                       0.0   \n",
       "\n",
       "   Other Ocean/Mexico_percentage  Other Tree Crops_acres  \\\n",
       "0                            0.0                8.673405   \n",
       "1                            0.0                0.000000   \n",
       "2                            0.0                1.334370   \n",
       "3                            0.0              790.391830   \n",
       "4                            0.0                0.889580   \n",
       "\n",
       "   Other Tree Crops_percentage  Other_acres  Other_percentage     Rice_acres  \\\n",
       "0                     0.002360          0.0               0.0       0.889580   \n",
       "1                     0.000000          0.0               0.0       0.000000   \n",
       "2                     0.000417          0.0               0.0       1.111975   \n",
       "3                     0.078443          0.0               0.0  105624.281300   \n",
       "4                     0.000140          0.0               0.0       0.000000   \n",
       "\n",
       "   Rice_percentage  Shrubland_acres  Shrubland_percentage  Tomatoes_acres  \\\n",
       "0         0.000242     30958.051185              8.423298        4.670295   \n",
       "1         0.000000    247783.390805             52.535935        0.000000   \n",
       "2         0.000347     52457.865415             16.379744        0.000000   \n",
       "3        10.482705     55372.129495              5.495419       94.295480   \n",
       "4         0.000000    106091.088405             16.715249        0.000000   \n",
       "\n",
       "   Tomatoes_percentage  Vegs & Fruits_acres  Vegs & Fruits_percentage  \\\n",
       "0             0.001271           164.127510                  0.044657   \n",
       "1             0.000000             0.000000                  0.000000   \n",
       "2             0.000000             1.779160                  0.000556   \n",
       "3             0.009358           469.475845                  0.046593   \n",
       "4             0.000000             0.667185                  0.000105   \n",
       "\n",
       "   Walnuts_acres  Walnuts_percentage   Water_acres  Water_percentage  \\\n",
       "0       4.670295            0.001271  19403.518960          5.279454   \n",
       "1       0.000000            0.000000   2650.503610          0.561969   \n",
       "2     122.094855            0.038124   5822.745890          1.818128   \n",
       "3   42057.340845            4.173990  21360.372565          2.119915   \n",
       "4     425.664030            0.067066  13178.682910          2.076376   \n",
       "\n",
       "   Wetlands_acres  Wetlands_percentage  Winter Wheat_acres  \\\n",
       "0     4497.494085             1.223712          624.485160   \n",
       "1     1297.452430             0.275091            0.000000   \n",
       "2      105.860020             0.033054          479.483620   \n",
       "3    11589.893030             1.150241         4257.085090   \n",
       "4      245.079290             0.038614           11.786935   \n",
       "\n",
       "   Winter Wheat_percentage  max_elevation  min_elevation  \\\n",
       "0                 0.169915           1242            -42   \n",
       "1                 0.000000           3556           1442   \n",
       "2                 0.149717           3121             43   \n",
       "3                 0.422495           2192             -1   \n",
       "4                 0.001857           3522            787   \n",
       "\n",
       "   Avg Air Temp (F)_Weekly  Avg Rel Hum (%)_Weekly  \\\n",
       "0                44.214286               82.785714   \n",
       "1                29.657143               76.514286   \n",
       "2                34.114286               83.571429   \n",
       "3                40.985714               81.285714   \n",
       "4                41.928571               93.014286   \n",
       "\n",
       "   Avg Wind Speed (mph)_Weekly  Dew Point (F)_Weekly  Max Air Temp (F)_Weekly  \\\n",
       "0                     2.392857             39.321429                54.157143   \n",
       "1                     3.228571             21.328571                34.428571   \n",
       "2                     3.157143             29.585714                40.071429   \n",
       "3                     3.142857             35.557143                50.114286   \n",
       "4                     5.657143             39.000000                50.142857   \n",
       "\n",
       "   Max Rel Hum (%)_Weekly  Min Air Temp (F)_Weekly  Min Rel Hum (%)_Weekly  \\\n",
       "0               96.500000                35.771429               60.785714   \n",
       "1               91.857143                22.857143               55.428571   \n",
       "2               96.000000                27.757143               66.571429   \n",
       "3               91.285714                32.171429               62.857143   \n",
       "4              100.000000                35.571429               74.142857   \n",
       "\n",
       "   Precip (in)_Weekly  Avg Air Temp (F)_month  Avg Rel Hum (%)_month  \\\n",
       "0            0.095714               45.506897              78.189655   \n",
       "1            0.000000               30.789655              68.162069   \n",
       "2            0.141429               34.289655              76.724138   \n",
       "3            0.117143               42.389655              77.448276   \n",
       "4            0.000000               42.931034              87.017241   \n",
       "\n",
       "   Avg Wind Speed (mph)_month  Dew Point (F)_month  Max Air Temp (F)_month  \\\n",
       "0                    2.915517            38.932759               55.896552   \n",
       "1                    4.968966            19.600000               39.344828   \n",
       "2                    3.606897            27.410345               41.200000   \n",
       "3                    3.848276            35.586207               52.455172   \n",
       "4                    6.268966            37.196552               52.827586   \n",
       "\n",
       "   Max Rel Hum (%)_month  Min Air Temp (F)_month  Min Rel Hum (%)_month  \\\n",
       "0              95.448276               35.725862              55.810345   \n",
       "1              86.000000               22.758621              46.344828   \n",
       "2              93.172414               27.768966              58.310345   \n",
       "3              88.965517               33.365517              58.862069   \n",
       "4              97.551724               34.344828              61.275862   \n",
       "\n",
       "   Precip (in)_month  \n",
       "0           0.130172  \n",
       "1           0.000000  \n",
       "2           0.155517  \n",
       "3           0.175517  \n",
       "4           0.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18154 entries, 0 to 18153\n",
      "Data columns (total 79 columns):\n",
      "Unnamed: 0                             18154 non-null int64\n",
      "date                                   18154 non-null object\n",
      "county                                 18154 non-null object\n",
      "year                                   18154 non-null int64\n",
      "acres_burned                           18154 non-null float64\n",
      "fire_started                           18154 non-null float64\n",
      "Unnamed: 0.1                           18154 non-null int64\n",
      "Alfalfa & Hay_acres                    18154 non-null float64\n",
      "Alfalfa & Hay_percentage               18154 non-null float64\n",
      "Almonds_acres                          18154 non-null float64\n",
      "Almonds_percentage                     18154 non-null float64\n",
      "Barren_acres                           18154 non-null float64\n",
      "Barren_percentage                      18154 non-null float64\n",
      "Corn_acres                             18154 non-null float64\n",
      "Corn_percentage                        18154 non-null float64\n",
      "Cotton_acres                           18154 non-null float64\n",
      "Cotton_percentage                      18154 non-null float64\n",
      "Deciduous Forest_acres                 18154 non-null float64\n",
      "Deciduous Forest_percentage            18154 non-null float64\n",
      "Evergreen Forest_acres                 18154 non-null float64\n",
      "Evergreen Forest_percentage            18154 non-null float64\n",
      "Fallow_acres                           18154 non-null float64\n",
      "Fallow_percentage                      18154 non-null float64\n",
      "Fruit Trees_acres                      18154 non-null float64\n",
      "Fruit Trees_percentage                 18154 non-null float64\n",
      "Grain Crops_acres                      18154 non-null float64\n",
      "Grain Crops_percentage                 18154 non-null float64\n",
      "Grapes_acres                           18154 non-null float64\n",
      "Grapes_percentage                      18154 non-null float64\n",
      "Grassland_acres                        18154 non-null float64\n",
      "Grassland_percentage                   18154 non-null float64\n",
      "High Intensity Developed_acres         18154 non-null float64\n",
      "High Intensity Developed_percentage    18154 non-null float64\n",
      "Low Intensity Developed_acres          18154 non-null float64\n",
      "Low Intensity Developed_percentage     18154 non-null float64\n",
      "Mixed Forest_acres                     18154 non-null float64\n",
      "Mixed Forest_percentage                18154 non-null float64\n",
      "Other Ocean/Mexico_acres               18154 non-null float64\n",
      "Other Ocean/Mexico_percentage          18154 non-null float64\n",
      "Other Tree Crops_acres                 18154 non-null float64\n",
      "Other Tree Crops_percentage            18154 non-null float64\n",
      "Other_acres                            18154 non-null float64\n",
      "Other_percentage                       18154 non-null float64\n",
      "Rice_acres                             18154 non-null float64\n",
      "Rice_percentage                        18154 non-null float64\n",
      "Shrubland_acres                        18154 non-null float64\n",
      "Shrubland_percentage                   18154 non-null float64\n",
      "Tomatoes_acres                         18154 non-null float64\n",
      "Tomatoes_percentage                    18154 non-null float64\n",
      "Vegs & Fruits_acres                    18154 non-null float64\n",
      "Vegs & Fruits_percentage               18154 non-null float64\n",
      "Walnuts_acres                          18154 non-null float64\n",
      "Walnuts_percentage                     18154 non-null float64\n",
      "Water_acres                            18154 non-null float64\n",
      "Water_percentage                       18154 non-null float64\n",
      "Wetlands_acres                         18154 non-null float64\n",
      "Wetlands_percentage                    18154 non-null float64\n",
      "Winter Wheat_acres                     18154 non-null float64\n",
      "Winter Wheat_percentage                18154 non-null float64\n",
      "max_elevation                          18154 non-null int64\n",
      "min_elevation                          18154 non-null int64\n",
      "Avg Air Temp (F)_Weekly                18154 non-null float64\n",
      "Avg Rel Hum (%)_Weekly                 18154 non-null float64\n",
      "Avg Wind Speed (mph)_Weekly            18154 non-null float64\n",
      "Dew Point (F)_Weekly                   18154 non-null float64\n",
      "Max Air Temp (F)_Weekly                18154 non-null float64\n",
      "Max Rel Hum (%)_Weekly                 18154 non-null float64\n",
      "Min Air Temp (F)_Weekly                18154 non-null float64\n",
      "Min Rel Hum (%)_Weekly                 18154 non-null float64\n",
      "Precip (in)_Weekly                     18154 non-null float64\n",
      "Avg Air Temp (F)_month                 18154 non-null float64\n",
      "Avg Rel Hum (%)_month                  18154 non-null float64\n",
      "Avg Wind Speed (mph)_month             18154 non-null float64\n",
      "Dew Point (F)_month                    18154 non-null float64\n",
      "Max Air Temp (F)_month                 18154 non-null float64\n",
      "Max Rel Hum (%)_month                  18154 non-null float64\n",
      "Min Air Temp (F)_month                 18154 non-null float64\n",
      "Min Rel Hum (%)_month                  18154 non-null float64\n",
      "Precip (in)_month                      18154 non-null float64\n",
      "dtypes: float64(72), int64(5), object(2)\n",
      "memory usage: 10.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = pd.get_dummies(df.county, drop_first = True)\n",
    "df2 = df.drop(columns = ['Unnamed: 0', 'Unnamed: 0.1', 'county', 'year', 'acres_burned'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['month'] = pd.DatetimeIndex(df2['date']).month\n",
    "df2.drop(columns = ['date'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df2, counties], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fire_started</th>\n",
       "      <th>Alfalfa &amp; Hay_acres</th>\n",
       "      <th>Alfalfa &amp; Hay_percentage</th>\n",
       "      <th>Almonds_acres</th>\n",
       "      <th>Almonds_percentage</th>\n",
       "      <th>Barren_acres</th>\n",
       "      <th>Barren_percentage</th>\n",
       "      <th>Corn_acres</th>\n",
       "      <th>Corn_percentage</th>\n",
       "      <th>Cotton_acres</th>\n",
       "      <th>Cotton_percentage</th>\n",
       "      <th>Deciduous Forest_acres</th>\n",
       "      <th>Deciduous Forest_percentage</th>\n",
       "      <th>Evergreen Forest_acres</th>\n",
       "      <th>Evergreen Forest_percentage</th>\n",
       "      <th>Fallow_acres</th>\n",
       "      <th>Fallow_percentage</th>\n",
       "      <th>Fruit Trees_acres</th>\n",
       "      <th>Fruit Trees_percentage</th>\n",
       "      <th>Grain Crops_acres</th>\n",
       "      <th>Grain Crops_percentage</th>\n",
       "      <th>Grapes_acres</th>\n",
       "      <th>Grapes_percentage</th>\n",
       "      <th>Grassland_acres</th>\n",
       "      <th>Grassland_percentage</th>\n",
       "      <th>High Intensity Developed_acres</th>\n",
       "      <th>High Intensity Developed_percentage</th>\n",
       "      <th>Low Intensity Developed_acres</th>\n",
       "      <th>Low Intensity Developed_percentage</th>\n",
       "      <th>Mixed Forest_acres</th>\n",
       "      <th>Mixed Forest_percentage</th>\n",
       "      <th>Other Ocean/Mexico_acres</th>\n",
       "      <th>Other Ocean/Mexico_percentage</th>\n",
       "      <th>Other Tree Crops_acres</th>\n",
       "      <th>Other Tree Crops_percentage</th>\n",
       "      <th>Other_acres</th>\n",
       "      <th>Other_percentage</th>\n",
       "      <th>Rice_acres</th>\n",
       "      <th>Rice_percentage</th>\n",
       "      <th>Shrubland_acres</th>\n",
       "      <th>Shrubland_percentage</th>\n",
       "      <th>Tomatoes_acres</th>\n",
       "      <th>Tomatoes_percentage</th>\n",
       "      <th>Vegs &amp; Fruits_acres</th>\n",
       "      <th>Vegs &amp; Fruits_percentage</th>\n",
       "      <th>Walnuts_acres</th>\n",
       "      <th>Walnuts_percentage</th>\n",
       "      <th>Water_acres</th>\n",
       "      <th>Water_percentage</th>\n",
       "      <th>Wetlands_acres</th>\n",
       "      <th>Wetlands_percentage</th>\n",
       "      <th>Winter Wheat_acres</th>\n",
       "      <th>Winter Wheat_percentage</th>\n",
       "      <th>max_elevation</th>\n",
       "      <th>min_elevation</th>\n",
       "      <th>Avg Air Temp (F)_Weekly</th>\n",
       "      <th>Avg Rel Hum (%)_Weekly</th>\n",
       "      <th>Avg Wind Speed (mph)_Weekly</th>\n",
       "      <th>Dew Point (F)_Weekly</th>\n",
       "      <th>Max Air Temp (F)_Weekly</th>\n",
       "      <th>Max Rel Hum (%)_Weekly</th>\n",
       "      <th>Min Air Temp (F)_Weekly</th>\n",
       "      <th>Min Rel Hum (%)_Weekly</th>\n",
       "      <th>Precip (in)_Weekly</th>\n",
       "      <th>Avg Air Temp (F)_month</th>\n",
       "      <th>Avg Rel Hum (%)_month</th>\n",
       "      <th>Avg Wind Speed (mph)_month</th>\n",
       "      <th>Dew Point (F)_month</th>\n",
       "      <th>Max Air Temp (F)_month</th>\n",
       "      <th>Max Rel Hum (%)_month</th>\n",
       "      <th>Min Air Temp (F)_month</th>\n",
       "      <th>Min Rel Hum (%)_month</th>\n",
       "      <th>Precip (in)_month</th>\n",
       "      <th>month</th>\n",
       "      <th>Alpine</th>\n",
       "      <th>Amador</th>\n",
       "      <th>Butte</th>\n",
       "      <th>Calaveras</th>\n",
       "      <th>Colusa</th>\n",
       "      <th>Contra Costa</th>\n",
       "      <th>Del Norte</th>\n",
       "      <th>El Dorado</th>\n",
       "      <th>Fresno</th>\n",
       "      <th>Glenn</th>\n",
       "      <th>Humboldt</th>\n",
       "      <th>Imperial</th>\n",
       "      <th>Inyo</th>\n",
       "      <th>Kern</th>\n",
       "      <th>Kings</th>\n",
       "      <th>Lake</th>\n",
       "      <th>Lassen</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>Madera</th>\n",
       "      <th>Marin</th>\n",
       "      <th>Mariposa</th>\n",
       "      <th>Mendocino</th>\n",
       "      <th>Merced</th>\n",
       "      <th>Modoc</th>\n",
       "      <th>Mono</th>\n",
       "      <th>Monterey</th>\n",
       "      <th>Napa</th>\n",
       "      <th>Nevada</th>\n",
       "      <th>Orange</th>\n",
       "      <th>Placer</th>\n",
       "      <th>Plumas</th>\n",
       "      <th>Riverside</th>\n",
       "      <th>Sacramento</th>\n",
       "      <th>San Benito</th>\n",
       "      <th>San Bernardino</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>San Joaquin</th>\n",
       "      <th>San Luis Obispo</th>\n",
       "      <th>San Mateo</th>\n",
       "      <th>Santa Barbara</th>\n",
       "      <th>Santa Clara</th>\n",
       "      <th>Santa Cruz</th>\n",
       "      <th>Shasta</th>\n",
       "      <th>Sierra</th>\n",
       "      <th>Siskiyou</th>\n",
       "      <th>Solano</th>\n",
       "      <th>Sonoma</th>\n",
       "      <th>Stanislaus</th>\n",
       "      <th>Sutter</th>\n",
       "      <th>Tehama</th>\n",
       "      <th>Trinity</th>\n",
       "      <th>Tulare</th>\n",
       "      <th>Tuolumne</th>\n",
       "      <th>Ventura</th>\n",
       "      <th>Yolo</th>\n",
       "      <th>Yuba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1102.856805</td>\n",
       "      <td>0.300074</td>\n",
       "      <td>4.225505</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>194.595625</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>4.670295</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.337480</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>7838.756565</td>\n",
       "      <td>2.132827</td>\n",
       "      <td>1536.749450</td>\n",
       "      <td>0.418130</td>\n",
       "      <td>1.779160</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>991.214515</td>\n",
       "      <td>0.269697</td>\n",
       "      <td>3722.447510</td>\n",
       "      <td>1.012831</td>\n",
       "      <td>153671.386680</td>\n",
       "      <td>41.812059</td>\n",
       "      <td>28431.421590</td>\n",
       "      <td>7.735834</td>\n",
       "      <td>39470.886995</td>\n",
       "      <td>10.739534</td>\n",
       "      <td>74885.956375</td>\n",
       "      <td>20.375531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.673405</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889580</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>30958.051185</td>\n",
       "      <td>8.423298</td>\n",
       "      <td>4.670295</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>164.127510</td>\n",
       "      <td>0.044657</td>\n",
       "      <td>4.670295</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>19403.518960</td>\n",
       "      <td>5.279454</td>\n",
       "      <td>4497.494085</td>\n",
       "      <td>1.223712</td>\n",
       "      <td>624.485160</td>\n",
       "      <td>0.169915</td>\n",
       "      <td>1242</td>\n",
       "      <td>-42</td>\n",
       "      <td>44.214286</td>\n",
       "      <td>82.785714</td>\n",
       "      <td>2.392857</td>\n",
       "      <td>39.321429</td>\n",
       "      <td>54.157143</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>35.771429</td>\n",
       "      <td>60.785714</td>\n",
       "      <td>0.095714</td>\n",
       "      <td>45.506897</td>\n",
       "      <td>78.189655</td>\n",
       "      <td>2.915517</td>\n",
       "      <td>38.932759</td>\n",
       "      <td>55.896552</td>\n",
       "      <td>95.448276</td>\n",
       "      <td>35.725862</td>\n",
       "      <td>55.810345</td>\n",
       "      <td>0.130172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>189.035750</td>\n",
       "      <td>0.040080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15482.472715</td>\n",
       "      <td>3.282650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>194.595625</td>\n",
       "      <td>0.041259</td>\n",
       "      <td>195088.007530</td>\n",
       "      <td>41.363269</td>\n",
       "      <td>0.444790</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.222395</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5644.829890</td>\n",
       "      <td>1.196837</td>\n",
       "      <td>121.427670</td>\n",
       "      <td>0.025746</td>\n",
       "      <td>3192.480225</td>\n",
       "      <td>0.676881</td>\n",
       "      <td>0.667185</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>247783.390805</td>\n",
       "      <td>52.535935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2650.503610</td>\n",
       "      <td>0.561969</td>\n",
       "      <td>1297.452430</td>\n",
       "      <td>0.275091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3556</td>\n",
       "      <td>1442</td>\n",
       "      <td>29.657143</td>\n",
       "      <td>76.514286</td>\n",
       "      <td>3.228571</td>\n",
       "      <td>21.328571</td>\n",
       "      <td>34.428571</td>\n",
       "      <td>91.857143</td>\n",
       "      <td>22.857143</td>\n",
       "      <td>55.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.789655</td>\n",
       "      <td>68.162069</td>\n",
       "      <td>4.968966</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>39.344828</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>22.758621</td>\n",
       "      <td>46.344828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1326.808570</td>\n",
       "      <td>0.414290</td>\n",
       "      <td>16.679625</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>1873.010690</td>\n",
       "      <td>0.584840</td>\n",
       "      <td>242.632945</td>\n",
       "      <td>0.075761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17190.911105</td>\n",
       "      <td>5.367789</td>\n",
       "      <td>114386.866695</td>\n",
       "      <td>35.716810</td>\n",
       "      <td>168.130620</td>\n",
       "      <td>0.052498</td>\n",
       "      <td>12.009330</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>120.093300</td>\n",
       "      <td>0.037499</td>\n",
       "      <td>2587.343430</td>\n",
       "      <td>0.807887</td>\n",
       "      <td>112912.610240</td>\n",
       "      <td>35.256480</td>\n",
       "      <td>440.119705</td>\n",
       "      <td>0.137425</td>\n",
       "      <td>8263.975805</td>\n",
       "      <td>2.580391</td>\n",
       "      <td>1727.119570</td>\n",
       "      <td>0.539286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.334370</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111975</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>52457.865415</td>\n",
       "      <td>16.379744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.779160</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>122.094855</td>\n",
       "      <td>0.038124</td>\n",
       "      <td>5822.745890</td>\n",
       "      <td>1.818128</td>\n",
       "      <td>105.860020</td>\n",
       "      <td>0.033054</td>\n",
       "      <td>479.483620</td>\n",
       "      <td>0.149717</td>\n",
       "      <td>3121</td>\n",
       "      <td>43</td>\n",
       "      <td>34.114286</td>\n",
       "      <td>83.571429</td>\n",
       "      <td>3.157143</td>\n",
       "      <td>29.585714</td>\n",
       "      <td>40.071429</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>27.757143</td>\n",
       "      <td>66.571429</td>\n",
       "      <td>0.141429</td>\n",
       "      <td>34.289655</td>\n",
       "      <td>76.724138</td>\n",
       "      <td>3.606897</td>\n",
       "      <td>27.410345</td>\n",
       "      <td>41.200000</td>\n",
       "      <td>93.172414</td>\n",
       "      <td>27.768966</td>\n",
       "      <td>58.310345</td>\n",
       "      <td>0.155517</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3777.156680</td>\n",
       "      <td>0.374865</td>\n",
       "      <td>46196.556585</td>\n",
       "      <td>4.584787</td>\n",
       "      <td>1869.452370</td>\n",
       "      <td>0.185534</td>\n",
       "      <td>2023.349710</td>\n",
       "      <td>0.200808</td>\n",
       "      <td>9.118195</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>33181.556395</td>\n",
       "      <td>3.293111</td>\n",
       "      <td>408193.790775</td>\n",
       "      <td>40.511281</td>\n",
       "      <td>56434.510410</td>\n",
       "      <td>5.600855</td>\n",
       "      <td>10563.317710</td>\n",
       "      <td>1.048359</td>\n",
       "      <td>2628.041715</td>\n",
       "      <td>0.260821</td>\n",
       "      <td>247.525635</td>\n",
       "      <td>0.024566</td>\n",
       "      <td>170758.216925</td>\n",
       "      <td>16.946936</td>\n",
       "      <td>4421.657390</td>\n",
       "      <td>0.438828</td>\n",
       "      <td>25520.048645</td>\n",
       "      <td>2.532743</td>\n",
       "      <td>165.684275</td>\n",
       "      <td>0.016443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>790.391830</td>\n",
       "      <td>0.078443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105624.281300</td>\n",
       "      <td>10.482705</td>\n",
       "      <td>55372.129495</td>\n",
       "      <td>5.495419</td>\n",
       "      <td>94.295480</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>469.475845</td>\n",
       "      <td>0.046593</td>\n",
       "      <td>42057.340845</td>\n",
       "      <td>4.173990</td>\n",
       "      <td>21360.372565</td>\n",
       "      <td>2.119915</td>\n",
       "      <td>11589.893030</td>\n",
       "      <td>1.150241</td>\n",
       "      <td>4257.085090</td>\n",
       "      <td>0.422495</td>\n",
       "      <td>2192</td>\n",
       "      <td>-1</td>\n",
       "      <td>40.985714</td>\n",
       "      <td>81.285714</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>35.557143</td>\n",
       "      <td>50.114286</td>\n",
       "      <td>91.285714</td>\n",
       "      <td>32.171429</td>\n",
       "      <td>62.857143</td>\n",
       "      <td>0.117143</td>\n",
       "      <td>42.389655</td>\n",
       "      <td>77.448276</td>\n",
       "      <td>3.848276</td>\n",
       "      <td>35.586207</td>\n",
       "      <td>52.455172</td>\n",
       "      <td>88.965517</td>\n",
       "      <td>33.365517</td>\n",
       "      <td>58.862069</td>\n",
       "      <td>0.175517</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31.802485</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>28.466560</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>218.391890</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.889580</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34882.878145</td>\n",
       "      <td>5.495994</td>\n",
       "      <td>255438.004310</td>\n",
       "      <td>40.245698</td>\n",
       "      <td>28.688955</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>12.231725</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>2.223950</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>522.183460</td>\n",
       "      <td>0.082273</td>\n",
       "      <td>207502.763615</td>\n",
       "      <td>32.693230</td>\n",
       "      <td>465.027945</td>\n",
       "      <td>0.073268</td>\n",
       "      <td>12257.745215</td>\n",
       "      <td>1.931277</td>\n",
       "      <td>3351.270255</td>\n",
       "      <td>0.528012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889580</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106091.088405</td>\n",
       "      <td>16.715249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667185</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>425.664030</td>\n",
       "      <td>0.067066</td>\n",
       "      <td>13178.682910</td>\n",
       "      <td>2.076376</td>\n",
       "      <td>245.079290</td>\n",
       "      <td>0.038614</td>\n",
       "      <td>11.786935</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>3522</td>\n",
       "      <td>787</td>\n",
       "      <td>41.928571</td>\n",
       "      <td>93.014286</td>\n",
       "      <td>5.657143</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>50.142857</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.571429</td>\n",
       "      <td>74.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.931034</td>\n",
       "      <td>87.017241</td>\n",
       "      <td>6.268966</td>\n",
       "      <td>37.196552</td>\n",
       "      <td>52.827586</td>\n",
       "      <td>97.551724</td>\n",
       "      <td>34.344828</td>\n",
       "      <td>61.275862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fire_started  Alfalfa & Hay_acres  Alfalfa & Hay_percentage  Almonds_acres  \\\n",
       "0           0.0          1102.856805                  0.300074       4.225505   \n",
       "1           0.0           189.035750                  0.040080       0.000000   \n",
       "2           0.0          1326.808570                  0.414290      16.679625   \n",
       "3           0.0          3777.156680                  0.374865   46196.556585   \n",
       "4           0.0            31.802485                  0.005011      28.466560   \n",
       "\n",
       "   Almonds_percentage  Barren_acres  Barren_percentage   Corn_acres  \\\n",
       "0            0.001150    194.595625           0.052947     4.670295   \n",
       "1            0.000000  15482.472715           3.282650     0.000000   \n",
       "2            0.005208   1873.010690           0.584840   242.632945   \n",
       "3            4.584787   1869.452370           0.185534  2023.349710   \n",
       "4            0.004485    218.391890           0.034409     0.889580   \n",
       "\n",
       "   Corn_percentage  Cotton_acres  Cotton_percentage  Deciduous Forest_acres  \\\n",
       "0         0.001271      0.000000           0.000000                5.337480   \n",
       "1         0.000000      0.000000           0.000000              194.595625   \n",
       "2         0.075761      0.000000           0.000000            17190.911105   \n",
       "3         0.200808      9.118195           0.000905            33181.556395   \n",
       "4         0.000140      0.000000           0.000000            34882.878145   \n",
       "\n",
       "   Deciduous Forest_percentage  Evergreen Forest_acres  \\\n",
       "0                     0.001452             7838.756565   \n",
       "1                     0.041259           195088.007530   \n",
       "2                     5.367789           114386.866695   \n",
       "3                     3.293111           408193.790775   \n",
       "4                     5.495994           255438.004310   \n",
       "\n",
       "   Evergreen Forest_percentage  Fallow_acres  Fallow_percentage  \\\n",
       "0                     2.132827   1536.749450           0.418130   \n",
       "1                    41.363269      0.444790           0.000094   \n",
       "2                    35.716810    168.130620           0.052498   \n",
       "3                    40.511281  56434.510410           5.600855   \n",
       "4                    40.245698     28.688955           0.004520   \n",
       "\n",
       "   Fruit Trees_acres  Fruit Trees_percentage  Grain Crops_acres  \\\n",
       "0           1.779160                0.000484         991.214515   \n",
       "1           0.222395                0.000047           0.000000   \n",
       "2          12.009330                0.003750         120.093300   \n",
       "3       10563.317710                1.048359        2628.041715   \n",
       "4          12.231725                0.001927           2.223950   \n",
       "\n",
       "   Grain Crops_percentage  Grapes_acres  Grapes_percentage  Grassland_acres  \\\n",
       "0                0.269697   3722.447510           1.012831    153671.386680   \n",
       "1                0.000000      0.000000           0.000000      5644.829890   \n",
       "2                0.037499   2587.343430           0.807887    112912.610240   \n",
       "3                0.260821    247.525635           0.024566    170758.216925   \n",
       "4                0.000350    522.183460           0.082273    207502.763615   \n",
       "\n",
       "   Grassland_percentage  High Intensity Developed_acres  \\\n",
       "0             41.812059                    28431.421590   \n",
       "1              1.196837                      121.427670   \n",
       "2             35.256480                      440.119705   \n",
       "3             16.946936                     4421.657390   \n",
       "4             32.693230                      465.027945   \n",
       "\n",
       "   High Intensity Developed_percentage  Low Intensity Developed_acres  \\\n",
       "0                             7.735834                   39470.886995   \n",
       "1                             0.025746                    3192.480225   \n",
       "2                             0.137425                    8263.975805   \n",
       "3                             0.438828                   25520.048645   \n",
       "4                             0.073268                   12257.745215   \n",
       "\n",
       "   Low Intensity Developed_percentage  Mixed Forest_acres  \\\n",
       "0                           10.739534        74885.956375   \n",
       "1                            0.676881            0.667185   \n",
       "2                            2.580391         1727.119570   \n",
       "3                            2.532743          165.684275   \n",
       "4                            1.931277         3351.270255   \n",
       "\n",
       "   Mixed Forest_percentage  Other Ocean/Mexico_acres  \\\n",
       "0                20.375531                       0.0   \n",
       "1                 0.000141                       0.0   \n",
       "2                 0.539286                       0.0   \n",
       "3                 0.016443                       0.0   \n",
       "4                 0.528012                       0.0   \n",
       "\n",
       "   Other Ocean/Mexico_percentage  Other Tree Crops_acres  \\\n",
       "0                            0.0                8.673405   \n",
       "1                            0.0                0.000000   \n",
       "2                            0.0                1.334370   \n",
       "3                            0.0              790.391830   \n",
       "4                            0.0                0.889580   \n",
       "\n",
       "   Other Tree Crops_percentage  Other_acres  Other_percentage     Rice_acres  \\\n",
       "0                     0.002360          0.0               0.0       0.889580   \n",
       "1                     0.000000          0.0               0.0       0.000000   \n",
       "2                     0.000417          0.0               0.0       1.111975   \n",
       "3                     0.078443          0.0               0.0  105624.281300   \n",
       "4                     0.000140          0.0               0.0       0.000000   \n",
       "\n",
       "   Rice_percentage  Shrubland_acres  Shrubland_percentage  Tomatoes_acres  \\\n",
       "0         0.000242     30958.051185              8.423298        4.670295   \n",
       "1         0.000000    247783.390805             52.535935        0.000000   \n",
       "2         0.000347     52457.865415             16.379744        0.000000   \n",
       "3        10.482705     55372.129495              5.495419       94.295480   \n",
       "4         0.000000    106091.088405             16.715249        0.000000   \n",
       "\n",
       "   Tomatoes_percentage  Vegs & Fruits_acres  Vegs & Fruits_percentage  \\\n",
       "0             0.001271           164.127510                  0.044657   \n",
       "1             0.000000             0.000000                  0.000000   \n",
       "2             0.000000             1.779160                  0.000556   \n",
       "3             0.009358           469.475845                  0.046593   \n",
       "4             0.000000             0.667185                  0.000105   \n",
       "\n",
       "   Walnuts_acres  Walnuts_percentage   Water_acres  Water_percentage  \\\n",
       "0       4.670295            0.001271  19403.518960          5.279454   \n",
       "1       0.000000            0.000000   2650.503610          0.561969   \n",
       "2     122.094855            0.038124   5822.745890          1.818128   \n",
       "3   42057.340845            4.173990  21360.372565          2.119915   \n",
       "4     425.664030            0.067066  13178.682910          2.076376   \n",
       "\n",
       "   Wetlands_acres  Wetlands_percentage  Winter Wheat_acres  \\\n",
       "0     4497.494085             1.223712          624.485160   \n",
       "1     1297.452430             0.275091            0.000000   \n",
       "2      105.860020             0.033054          479.483620   \n",
       "3    11589.893030             1.150241         4257.085090   \n",
       "4      245.079290             0.038614           11.786935   \n",
       "\n",
       "   Winter Wheat_percentage  max_elevation  min_elevation  \\\n",
       "0                 0.169915           1242            -42   \n",
       "1                 0.000000           3556           1442   \n",
       "2                 0.149717           3121             43   \n",
       "3                 0.422495           2192             -1   \n",
       "4                 0.001857           3522            787   \n",
       "\n",
       "   Avg Air Temp (F)_Weekly  Avg Rel Hum (%)_Weekly  \\\n",
       "0                44.214286               82.785714   \n",
       "1                29.657143               76.514286   \n",
       "2                34.114286               83.571429   \n",
       "3                40.985714               81.285714   \n",
       "4                41.928571               93.014286   \n",
       "\n",
       "   Avg Wind Speed (mph)_Weekly  Dew Point (F)_Weekly  Max Air Temp (F)_Weekly  \\\n",
       "0                     2.392857             39.321429                54.157143   \n",
       "1                     3.228571             21.328571                34.428571   \n",
       "2                     3.157143             29.585714                40.071429   \n",
       "3                     3.142857             35.557143                50.114286   \n",
       "4                     5.657143             39.000000                50.142857   \n",
       "\n",
       "   Max Rel Hum (%)_Weekly  Min Air Temp (F)_Weekly  Min Rel Hum (%)_Weekly  \\\n",
       "0               96.500000                35.771429               60.785714   \n",
       "1               91.857143                22.857143               55.428571   \n",
       "2               96.000000                27.757143               66.571429   \n",
       "3               91.285714                32.171429               62.857143   \n",
       "4              100.000000                35.571429               74.142857   \n",
       "\n",
       "   Precip (in)_Weekly  Avg Air Temp (F)_month  Avg Rel Hum (%)_month  \\\n",
       "0            0.095714               45.506897              78.189655   \n",
       "1            0.000000               30.789655              68.162069   \n",
       "2            0.141429               34.289655              76.724138   \n",
       "3            0.117143               42.389655              77.448276   \n",
       "4            0.000000               42.931034              87.017241   \n",
       "\n",
       "   Avg Wind Speed (mph)_month  Dew Point (F)_month  Max Air Temp (F)_month  \\\n",
       "0                    2.915517            38.932759               55.896552   \n",
       "1                    4.968966            19.600000               39.344828   \n",
       "2                    3.606897            27.410345               41.200000   \n",
       "3                    3.848276            35.586207               52.455172   \n",
       "4                    6.268966            37.196552               52.827586   \n",
       "\n",
       "   Max Rel Hum (%)_month  Min Air Temp (F)_month  Min Rel Hum (%)_month  \\\n",
       "0              95.448276               35.725862              55.810345   \n",
       "1              86.000000               22.758621              46.344828   \n",
       "2              93.172414               27.768966              58.310345   \n",
       "3              88.965517               33.365517              58.862069   \n",
       "4              97.551724               34.344828              61.275862   \n",
       "\n",
       "   Precip (in)_month  month  Alpine  Amador  Butte  Calaveras  Colusa  \\\n",
       "0           0.130172      1       0       0      0          0       0   \n",
       "1           0.000000      1       1       0      0          0       0   \n",
       "2           0.155517      1       0       1      0          0       0   \n",
       "3           0.175517      1       0       0      1          0       0   \n",
       "4           0.000000      1       0       0      0          1       0   \n",
       "\n",
       "   Contra Costa  Del Norte  El Dorado  Fresno  Glenn  Humboldt  Imperial  \\\n",
       "0             0          0          0       0      0         0         0   \n",
       "1             0          0          0       0      0         0         0   \n",
       "2             0          0          0       0      0         0         0   \n",
       "3             0          0          0       0      0         0         0   \n",
       "4             0          0          0       0      0         0         0   \n",
       "\n",
       "   Inyo  Kern  Kings  Lake  Lassen  Los Angeles  Madera  Marin  Mariposa  \\\n",
       "0     0     0      0     0       0            0       0      0         0   \n",
       "1     0     0      0     0       0            0       0      0         0   \n",
       "2     0     0      0     0       0            0       0      0         0   \n",
       "3     0     0      0     0       0            0       0      0         0   \n",
       "4     0     0      0     0       0            0       0      0         0   \n",
       "\n",
       "   Mendocino  Merced  Modoc  Mono  Monterey  Napa  Nevada  Orange  Placer  \\\n",
       "0          0       0      0     0         0     0       0       0       0   \n",
       "1          0       0      0     0         0     0       0       0       0   \n",
       "2          0       0      0     0         0     0       0       0       0   \n",
       "3          0       0      0     0         0     0       0       0       0   \n",
       "4          0       0      0     0         0     0       0       0       0   \n",
       "\n",
       "   Plumas  Riverside  Sacramento  San Benito  San Bernardino  San Diego  \\\n",
       "0       0          0           0           0               0          0   \n",
       "1       0          0           0           0               0          0   \n",
       "2       0          0           0           0               0          0   \n",
       "3       0          0           0           0               0          0   \n",
       "4       0          0           0           0               0          0   \n",
       "\n",
       "   San Francisco  San Joaquin  San Luis Obispo  San Mateo  Santa Barbara  \\\n",
       "0              0            0                0          0              0   \n",
       "1              0            0                0          0              0   \n",
       "2              0            0                0          0              0   \n",
       "3              0            0                0          0              0   \n",
       "4              0            0                0          0              0   \n",
       "\n",
       "   Santa Clara  Santa Cruz  Shasta  Sierra  Siskiyou  Solano  Sonoma  \\\n",
       "0            0           0       0       0         0       0       0   \n",
       "1            0           0       0       0         0       0       0   \n",
       "2            0           0       0       0         0       0       0   \n",
       "3            0           0       0       0         0       0       0   \n",
       "4            0           0       0       0         0       0       0   \n",
       "\n",
       "   Stanislaus  Sutter  Tehama  Trinity  Tulare  Tuolumne  Ventura  Yolo  Yuba  \n",
       "0           0       0       0        0       0         0        0     0     0  \n",
       "1           0       0       0        0       0         0        0     0     0  \n",
       "2           0       0       0        0       0         0        0     0     0  \n",
       "3           0       0       0        0       0         0        0     0     0  \n",
       "4           0       0       0        0       0         0        0     0     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2.fire_started\n",
    "X = df2.drop(columns = ['fire_started'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,  y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a baseline model to make sure that the data can run through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malcolmkatzenbach/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/malcolmkatzenbach/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = logreg.predict(X_train)\n",
    "y_hat_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n",
      "0.9410209327947117 0.9358889623265036\n",
      "0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malcolmkatzenbach/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix\n",
    "print(f1_score(y_train, y_hat_train), f1_score(y_test, y_hat_test))\n",
    "print(accuracy_score(y_train, y_hat_train), accuracy_score(y_test, y_hat_test))\n",
    "print(recall_score(y_train, y_hat_train), recall_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4248,    1],\n",
       "       [ 290,    0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the model is predicting that there is never a fire in California. Part of the problem, is the class imbalance. So the first change to make to the model is to account for class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 'Balanced' Class Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next model, we attempt to take into account the class imbalance by making the `class_weight` equal to `balanced`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malcolmkatzenbach/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/malcolmkatzenbach/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg1 = LogisticRegression(class_weight = 'balanced')\n",
    "logreg1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train1 = logreg1.predict(X_train)\n",
    "y_hat_test1 = logreg1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1928071928071928 0.1978557504873294\n",
      "0.643922144693353 0.6373650583829037\n",
      "0.7210460772104608 0.7\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_train, y_hat_train1), f1_score(y_test, y_hat_test1))\n",
    "print(accuracy_score(y_train, y_hat_train1), accuracy_score(y_test, y_hat_test1))\n",
    "print(recall_score(y_train, y_hat_train1), recall_score(y_test, y_hat_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our metrics, we notice that the recall is higher than the accuracy and there is a large difference between the recall and f1 score. We want to take a closer look by using a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2690, 1559],\n",
       "       [  87,  203]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above matrix, the large majority of our error is from falsely predicting that there is going to be a fire, when there is none. To deal with this, we will first plot the precision-recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malcolmkatzenbach/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/malcolmkatzenbach/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "y_score = logreg1.fit(X_train, y_train).decision_function(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0, 1], [0, 1])\n",
    "plt.plot(fpr, tpr, label = 'logistic')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2 = LogisticRegression(class_weight = {1:5, 0:1}, solver = 'liblinear')\n",
    "logreg2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train2 = logreg2.predict(X_train)\n",
    "y_hat_test2 = logreg2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_train, y_hat_train2), f1_score(y_test, y_hat_test2))\n",
    "print(accuracy_score(y_train, y_hat_train2), accuracy_score(y_test, y_hat_test2))\n",
    "print(recall_score(y_train, y_hat_train2), recall_score(y_test, y_hat_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "\n",
    "X_train_scaled = ss.transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg3 = LogisticRegression(class_weight = 'balanced', solver = 'liblinear')\n",
    "logreg3.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train3 = logreg3.predict(X_train_scaled)\n",
    "y_hat_test3 = logreg3.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28577371048252914 0.27069486404833837\n",
      "0.7477781858244583 0.7340823970037453\n",
      "0.8555417185554172 0.7724137931034483\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_train, y_hat_train3), f1_score(y_test, y_hat_test3))\n",
    "print(accuracy_score(y_train, y_hat_train3), accuracy_score(y_test, y_hat_test3))\n",
    "print(recall_score(y_train, y_hat_train3), recall_score(y_test, y_hat_test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Logistic Regression - Tuning Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg4 = LogisticRegression(class_weight = 'balanced', solver = 'liblinear', penalty = 'l1')\n",
    "logreg4.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train4 = logreg4.predict(X_train_scaled)\n",
    "y_hat_test4 = logreg4.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28506129233326405 0.2704967085577499\n",
      "0.7472640470069776 0.7314386428728795\n",
      "0.8542963885429639 0.7793103448275862\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_train, y_hat_train4), f1_score(y_test, y_hat_test4))\n",
    "print(accuracy_score(y_train, y_hat_train4), accuracy_score(y_test, y_hat_test4))\n",
    "print(recall_score(y_train, y_hat_train4), recall_score(y_test, y_hat_test4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor (KNN) Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I checked a base model of K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train = knn.predict(X_train_scaled)\n",
    "knn_test = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3711967545638945 0.1615598885793872\n",
      "0.9544619904517077 0.9336858338841154\n",
      "0.22789539227895392 0.1\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_train, knn_train), f1_score(y_test, knn_test))\n",
    "print(accuracy_score(y_train, knn_train), accuracy_score(y_test, knn_test))\n",
    "print(recall_score(y_train, knn_train), recall_score(y_test, knn_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base model has a higher training score than the logistic model, but the test score is lower. There is more over-fitting in this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Tuning n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_value(l):\n",
    "    max_val = max(l)\n",
    "    max_idx = l.index(max_val)\n",
    "    return max_idx, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.25043478260869567\n"
     ]
    }
   ],
   "source": [
    "k_scores = []\n",
    "k_range = list(range(1, 21))\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    k_scores.append(f1)\n",
    "\n",
    "idx, val = max_value(k_scores)\n",
    "print(idx + 1, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.25043478260869567\n",
      "1.0 0.905045164133069\n",
      "1.0 0.2482758620689655\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "knn_train1 = knn.predict(X_train_scaled)\n",
    "print(f1_score(y_train, knn_train1), f1_score(y_test, y_pred))\n",
    "print(accuracy_score(y_train, knn_train1), accuracy_score(y_test, y_pred))\n",
    "print(recall_score(y_train, knn_train1), recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has a lower test score than the logistic model and the model is highly over-fit, and thus would not be generalizable to new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we noticed in the logistic model, due to the high class imbalance, the class_weight should start as 'balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state = 0, class_weight = 'balanced')\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.22021660649819494\n",
      "1.0 0.9048248512888302\n",
      "1.0 0.2103448275862069\n"
     ]
    }
   ],
   "source": [
    "dt_train = dt.predict(X_train)\n",
    "dt_test = dt.predict(X_test)\n",
    "\n",
    "print(f1_score(y_train, dt_train), f1_score(y_test, dt_test))\n",
    "print(accuracy_score(y_train, dt_train), accuracy_score(y_test, dt_test))\n",
    "print(recall_score(y_train, dt_train), recall_score(y_test, dt_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the knn model, the decision tree model has the worst test score, and is also highly over-fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Parameters - GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth' : range(1, 21, 1), 'max_features' : range(1, 24, 1), 'min_samples_split' : range(2, 10, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3680 candidates, totalling 36800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 804 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1504 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2404 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3504 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 4804 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=-1)]: Done 6304 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 8004 tasks      | elapsed:   53.9s\n",
      "[Parallel(n_jobs=-1)]: Done 9904 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 12004 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 14304 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 16804 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 19504 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 22404 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 25504 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 28804 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 32304 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 36004 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 36800 out of 36800 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=0,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': range(1, 21),\n",
       "                         'max_features': range(1, 24),\n",
       "                         'min_samples_split': range(2, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtg = DecisionTreeClassifier(random_state = 0, class_weight = 'balanced')\n",
    "grid_model = GridSearchCV(dtg, parameters, cv = 10, scoring = 'f1', verbose = 1, n_jobs = -1)\n",
    "\n",
    "grid_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29886538852519356\n",
      "{'max_depth': 18, 'max_features': 15, 'min_samples_split': 6}\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=18,\n",
      "                       max_features=15, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=6,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=0, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(grid_model.best_score_)\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2747933884297521 0.845340383344349 0.4586206896551724\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_model.best_estimator_.predict(X_test)\n",
    "print(f1_score(y_test, y_pred), accuracy_score(y_test, y_pred), recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5661842569714084 0.9097319133308851 0.9987546699875467\n"
     ]
    }
   ],
   "source": [
    "dt_train2 = grid_model.best_estimator_.predict(X_train)\n",
    "print(f1_score(y_train, dt_train2), accuracy_score(y_train, dt_train2), recall_score(y_train, dt_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3704,  545],\n",
       "       [ 157,  133]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the base model, we will run a Random Forest Classifier (rfc) with a balanced `class_weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malcolmkatzenbach/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=10, n_jobs=None, oob_score=False,\n",
       "                       random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state = 0, class_weight = 'balanced')\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_train = rfc.predict(X_train)\n",
    "rfc_test = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9265687583444593 0.13445378151260504\n",
      "0.991920675725303 0.9319233311302049\n",
      "0.8642590286425903 0.08275862068965517\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_train, rfc_train), f1_score(y_test, rfc_test))\n",
    "print(accuracy_score(y_train, rfc_train), accuracy_score(y_test, rfc_test))\n",
    "print(recall_score(y_train, rfc_train), recall_score(y_test, rfc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4206,   43],\n",
       "       [ 266,   24]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, rfc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the error in the baseline model is predicting no fire when there is a fire (false negatives). We will tune the parameters of the model to decrease the number of false negatives. Also the model is highly overfit and thus not generalizable to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Model - GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the recall and precision of the model, we will use GridSearch with a scoring method of f1. The first parameters to check is the number of trees (`n_estimators`), the function for quality of the split (`criterion`), the number of samples required for a split (`min_samples_split`), and the number of features that the tree can consider when looking for the best split (`max_features`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [100,300],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': list(range(2,10)),\n",
    "    'max_features': list(range(3,7))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree=GridSearchCV(RandomForestClassifier(random_state = 0, class_weight = 'balanced'), param_grid, cv=5, scoring='f1', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False, random_state=0,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': [3, 4, 5, 6],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'n_estimators': [100, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32090104210441844\n",
      "{'criterion': 'entropy', 'max_features': 3, 'min_samples_split': 9, 'n_estimators': 100}\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=None, max_features=3,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=9, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                       random_state=0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_tree.best_score_)\n",
    "print(grid_tree.best_params_)\n",
    "print(grid_tree.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8238961038961039 0.33333333333333337\n",
      "0.9751009915534337 0.917162370566204\n",
      "0.987546699875467 0.32413793103448274\n"
     ]
    }
   ],
   "source": [
    "grid_tree_train = grid_tree.best_estimator_.predict(X_train)\n",
    "grid_tree_test = grid_tree.best_estimator_.predict(X_test)\n",
    "print(f1_score(y_train, grid_tree_train), f1_score(y_test, grid_tree_test))\n",
    "print(accuracy_score(y_train, grid_tree_train), accuracy_score(y_test, grid_tree_test))\n",
    "print(recall_score(y_train, grid_tree_train), recall_score(y_test, grid_tree_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4069,  180],\n",
       "       [ 196,   94]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, grid_tree_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is still highly overfit. The test scores have gotten better and due to using the f1 metric, the false negatives and false positives have a similar number with false negatives being slightly more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Model - GridSearch 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous model, we notice that the `n_estimators` was at its smallest possible number and the `min_samples_split` parameter was at its highest viewed possibility. To increase the test scores, we will decrease and increase their respective possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid2 = { \n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'min_samples_split': list(range(8, 15)),\n",
    "    'max_features': list(range(2,5))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree2 =GridSearchCV(RandomForestClassifier(criterion = 'entropy', random_state = 0, class_weight = 'balanced'), param_grid2, cv=5, scoring='f1', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 315 out of 315 | elapsed:   36.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='entropy',\n",
       "                                              max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False, random_state=0,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_features': [2, 3, 4],\n",
       "                         'min_samples_split': [8, 9, 10, 11, 12, 13, 14],\n",
       "                         'n_estimators': [50, 100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43213926455795243\n",
      "{'max_features': 2, 'min_samples_split': 14, 'n_estimators': 50}\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features=2,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=14, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=50, n_jobs=None, oob_score=False,\n",
      "                       random_state=0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_tree2.best_score_)\n",
    "print(grid_tree2.best_params_)\n",
    "print(grid_tree2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7314771118452101 0.34398782343987827\n",
      "0.9582078589790672 0.905045164133069\n",
      "0.9651307596513076 0.3896551724137931\n"
     ]
    }
   ],
   "source": [
    "grid_tree_train2 = grid_tree2.best_estimator_.predict(X_train)\n",
    "grid_tree_test2 = grid_tree2.best_estimator_.predict(X_test)\n",
    "print(f1_score(y_train, grid_tree_train2), f1_score(y_test, grid_tree_test2))\n",
    "print(accuracy_score(y_train, grid_tree_train2), accuracy_score(y_test, grid_tree_test2))\n",
    "print(recall_score(y_train, grid_tree_train2), recall_score(y_test, grid_tree_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3995,  254],\n",
       "       [ 177,  113]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, grid_tree_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test scores overall have gotten better. Though there is an increase in false positives. The difference in train and test values for f1 and recall show that there is still great deal of overfitting. The parameters mentioned in the previous model have repeated, thus the range of numbers will change for those parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Model - GridSearch 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next model we have increased the range of the `min_samples_split` and decreased the range for `n_estimators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid3 = { \n",
    "    'n_estimators': [25, 50, 75],\n",
    "    'min_samples_split': list(range(13, 25)),\n",
    "    'max_features': list(range(2,5))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree3 =GridSearchCV(RandomForestClassifier(criterion = 'entropy', random_state = 0, class_weight = 'balanced'), param_grid3, cv=5, scoring='f1', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:   31.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='entropy',\n",
       "                                              max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False, random_state=0,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_features': [2, 3, 4],\n",
       "                         'min_samples_split': [13, 14, 15, 16, 17, 18, 19, 20,\n",
       "                                               21, 22, 23, 24],\n",
       "                         'n_estimators': [25, 50, 75]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3475466612298669\n",
      "{'max_features': 2, 'min_samples_split': 18, 'n_estimators': 50}\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=None, max_features=2,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=18, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=50, n_jobs=None, oob_score=False,\n",
      "                       random_state=0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_tree3.best_score_)\n",
    "print(grid_tree3.best_params_)\n",
    "print(grid_tree3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_train3 = grid_tree3.best_estimator_.predict(X_train)\n",
    "rfc_test3 = grid_tree3.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6047087980173482 0.3346203346203346\n",
      "0.9297098788101359 0.8860982595285305\n",
      "0.9115815691158157 0.4482758620689655\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_train, rfc_train3), f1_score(y_test, rfc_test3))\n",
    "print(accuracy_score(y_train, rfc_train3), accuracy_score(y_test, rfc_test3))\n",
    "print(recall_score(y_train, rfc_train3), recall_score(y_test, rfc_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3892,  357],\n",
       "       [ 160,  130]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, rfc_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has once again been an increase in the false positives and decrease in the false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Model - GridSearch 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid4 = { \n",
    "    'n_estimators': [40, 50, 60],\n",
    "    'min_samples_split': list(range(20, 35)),\n",
    "    'max_features': list(range(2,5))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree4 =GridSearchCV(RandomForestClassifier(criterion = 'entropy', random_state = 0, class_weight = 'balanced'), param_grid4, cv=5, scoring='f1', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 675 out of 675 | elapsed:   35.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='entropy',\n",
       "                                              max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False, random_state=0,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_features': [2, 3, 4],\n",
       "                         'min_samples_split': [20, 21, 22, 23, 24, 25, 26, 27,\n",
       "                                               28, 29, 30, 31, 32, 33, 34],\n",
       "                         'n_estimators': [40, 50, 60]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3518842093244684\n",
      "{'max_features': 4, 'min_samples_split': 23, 'n_estimators': 60}\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=None, max_features=4,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=23, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=60, n_jobs=None, oob_score=False,\n",
      "                       random_state=0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_tree4.best_score_)\n",
    "print(grid_tree4.best_params_)\n",
    "print(grid_tree4.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_train4 = grid_tree4.best_estimator_.predict(X_train)\n",
    "rfc_test4 = grid_tree4.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6313109885447603 0.3351063829787234\n",
      "0.9361733382298935 0.8898435778805904\n",
      "0.9265255292652553 0.43448275862068964\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_train, rfc_train4), f1_score(y_test, rfc_test4))\n",
    "print(accuracy_score(y_train, rfc_train4), accuracy_score(y_test, rfc_test4))\n",
    "print(recall_score(y_train, rfc_train4), recall_score(y_test, rfc_test4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Model - GridSearch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid5 = { \n",
    "    'n_estimators': [55, 60, 65],\n",
    "    'min_samples_split': list(range(30, 45)),\n",
    "    'max_features': list(range(2,5))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree5 =GridSearchCV(RandomForestClassifier(criterion = 'entropy', random_state = 0, class_weight = 'balanced'), param_grid5, cv=5, scoring='f1', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 675 out of 675 | elapsed:   41.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='entropy',\n",
       "                                              max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False, random_state=0,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_features': [2, 3, 4],\n",
       "                         'min_samples_split': [30, 31, 32, 33, 34, 35, 36, 37,\n",
       "                                               38, 39, 40, 41, 42, 43, 44],\n",
       "                         'n_estimators': [55, 60, 65]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3497188855944589\n",
      "{'max_features': 4, 'min_samples_split': 36, 'n_estimators': 55}\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=None, max_features=4,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=36, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=55, n_jobs=None, oob_score=False,\n",
      "                       random_state=0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_tree5.best_score_)\n",
    "print(grid_tree5.best_params_)\n",
    "print(grid_tree5.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_train5 = grid_tree5.best_estimator_.predict(X_train)\n",
    "rfc_test5 = grid_tree5.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5514622104063805 0.34712643678160926\n",
      "0.9132574366507529 0.8748623044723507\n",
      "0.9041095890410958 0.5206896551724138\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_train, rfc_train5), f1_score(y_test, rfc_test5))\n",
    "print(accuracy_score(y_train, rfc_train5), accuracy_score(y_test, rfc_test5))\n",
    "print(recall_score(y_train, rfc_train5), recall_score(y_test, rfc_test5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3820,  429],\n",
       "       [ 139,  151]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, rfc_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
