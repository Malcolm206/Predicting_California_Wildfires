{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 300)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the California Wildfires dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/california_wildfires.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dummy Variables for Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two features that are categorical. The counties and the month of the year column that we engineered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for the county column\n",
    "counties = pd.get_dummies(df.county, drop_first = True)\n",
    "# Drop county column along with unnecessary columns (Unnamed columns, year, and acres burned)\n",
    "df2 = df.drop(columns = ['Unnamed: 0', 'Unnamed: 0.1', 'county', 'year', 'acres_burned'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineer month column from the date column\n",
    "df2['month'] = pd.DatetimeIndex(df2['date']).month\n",
    "# Drop the date column\n",
    "df2.drop(columns = ['date'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for the months\n",
    "month = pd.get_dummies(df2.month, drop_first = True)\n",
    "# Drop the month column\n",
    "df2.drop(columns = 'month', axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the original dataframe with the dummy variables\n",
    "df2 = pd.concat([df2, counties, month], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fire_started</th>\n",
       "      <th>Alfalfa &amp; Hay_acres</th>\n",
       "      <th>Alfalfa &amp; Hay_percentage</th>\n",
       "      <th>Almonds_acres</th>\n",
       "      <th>Almonds_percentage</th>\n",
       "      <th>Barren_acres</th>\n",
       "      <th>Barren_percentage</th>\n",
       "      <th>Corn_acres</th>\n",
       "      <th>Corn_percentage</th>\n",
       "      <th>Cotton_acres</th>\n",
       "      <th>Cotton_percentage</th>\n",
       "      <th>Deciduous Forest_acres</th>\n",
       "      <th>Deciduous Forest_percentage</th>\n",
       "      <th>Evergreen Forest_acres</th>\n",
       "      <th>Evergreen Forest_percentage</th>\n",
       "      <th>Fallow_acres</th>\n",
       "      <th>Fallow_percentage</th>\n",
       "      <th>Fruit Trees_acres</th>\n",
       "      <th>Fruit Trees_percentage</th>\n",
       "      <th>Grain Crops_acres</th>\n",
       "      <th>Grain Crops_percentage</th>\n",
       "      <th>Grapes_acres</th>\n",
       "      <th>Grapes_percentage</th>\n",
       "      <th>Grassland_acres</th>\n",
       "      <th>Grassland_percentage</th>\n",
       "      <th>High Intensity Developed_acres</th>\n",
       "      <th>High Intensity Developed_percentage</th>\n",
       "      <th>Low Intensity Developed_acres</th>\n",
       "      <th>Low Intensity Developed_percentage</th>\n",
       "      <th>Mixed Forest_acres</th>\n",
       "      <th>Mixed Forest_percentage</th>\n",
       "      <th>Other Ocean/Mexico_acres</th>\n",
       "      <th>Other Ocean/Mexico_percentage</th>\n",
       "      <th>Other Tree Crops_acres</th>\n",
       "      <th>Other Tree Crops_percentage</th>\n",
       "      <th>Other_acres</th>\n",
       "      <th>Other_percentage</th>\n",
       "      <th>Rice_acres</th>\n",
       "      <th>Rice_percentage</th>\n",
       "      <th>Shrubland_acres</th>\n",
       "      <th>Shrubland_percentage</th>\n",
       "      <th>Tomatoes_acres</th>\n",
       "      <th>Tomatoes_percentage</th>\n",
       "      <th>Vegs &amp; Fruits_acres</th>\n",
       "      <th>Vegs &amp; Fruits_percentage</th>\n",
       "      <th>Walnuts_acres</th>\n",
       "      <th>Walnuts_percentage</th>\n",
       "      <th>Water_acres</th>\n",
       "      <th>Water_percentage</th>\n",
       "      <th>Wetlands_acres</th>\n",
       "      <th>Wetlands_percentage</th>\n",
       "      <th>Winter Wheat_acres</th>\n",
       "      <th>Winter Wheat_percentage</th>\n",
       "      <th>max_elevation</th>\n",
       "      <th>min_elevation</th>\n",
       "      <th>Avg Air Temp (F)_Weekly</th>\n",
       "      <th>Avg Rel Hum (%)_Weekly</th>\n",
       "      <th>Avg Wind Speed (mph)_Weekly</th>\n",
       "      <th>Dew Point (F)_Weekly</th>\n",
       "      <th>Max Air Temp (F)_Weekly</th>\n",
       "      <th>Max Rel Hum (%)_Weekly</th>\n",
       "      <th>Min Air Temp (F)_Weekly</th>\n",
       "      <th>Min Rel Hum (%)_Weekly</th>\n",
       "      <th>Precip (in)_Weekly</th>\n",
       "      <th>Avg Air Temp (F)_month</th>\n",
       "      <th>Avg Rel Hum (%)_month</th>\n",
       "      <th>Avg Wind Speed (mph)_month</th>\n",
       "      <th>Dew Point (F)_month</th>\n",
       "      <th>Max Air Temp (F)_month</th>\n",
       "      <th>Max Rel Hum (%)_month</th>\n",
       "      <th>Min Air Temp (F)_month</th>\n",
       "      <th>Min Rel Hum (%)_month</th>\n",
       "      <th>Precip (in)_month</th>\n",
       "      <th>Alpine</th>\n",
       "      <th>Amador</th>\n",
       "      <th>Butte</th>\n",
       "      <th>Calaveras</th>\n",
       "      <th>Colusa</th>\n",
       "      <th>Contra Costa</th>\n",
       "      <th>Del Norte</th>\n",
       "      <th>El Dorado</th>\n",
       "      <th>Fresno</th>\n",
       "      <th>Glenn</th>\n",
       "      <th>Humboldt</th>\n",
       "      <th>Imperial</th>\n",
       "      <th>Inyo</th>\n",
       "      <th>Kern</th>\n",
       "      <th>Kings</th>\n",
       "      <th>Lake</th>\n",
       "      <th>Lassen</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>Madera</th>\n",
       "      <th>Marin</th>\n",
       "      <th>Mariposa</th>\n",
       "      <th>Mendocino</th>\n",
       "      <th>Merced</th>\n",
       "      <th>Modoc</th>\n",
       "      <th>Mono</th>\n",
       "      <th>Monterey</th>\n",
       "      <th>Napa</th>\n",
       "      <th>Nevada</th>\n",
       "      <th>Orange</th>\n",
       "      <th>Placer</th>\n",
       "      <th>Plumas</th>\n",
       "      <th>Riverside</th>\n",
       "      <th>Sacramento</th>\n",
       "      <th>San Benito</th>\n",
       "      <th>San Bernardino</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>San Joaquin</th>\n",
       "      <th>San Luis Obispo</th>\n",
       "      <th>San Mateo</th>\n",
       "      <th>Santa Barbara</th>\n",
       "      <th>Santa Clara</th>\n",
       "      <th>Santa Cruz</th>\n",
       "      <th>Shasta</th>\n",
       "      <th>Sierra</th>\n",
       "      <th>Siskiyou</th>\n",
       "      <th>Solano</th>\n",
       "      <th>Sonoma</th>\n",
       "      <th>Stanislaus</th>\n",
       "      <th>Sutter</th>\n",
       "      <th>Tehama</th>\n",
       "      <th>Trinity</th>\n",
       "      <th>Tulare</th>\n",
       "      <th>Tuolumne</th>\n",
       "      <th>Ventura</th>\n",
       "      <th>Yolo</th>\n",
       "      <th>Yuba</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1102.856805</td>\n",
       "      <td>0.300074</td>\n",
       "      <td>4.225505</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>194.595625</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>4.670295</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.337480</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>7838.756565</td>\n",
       "      <td>2.132827</td>\n",
       "      <td>1536.749450</td>\n",
       "      <td>0.418130</td>\n",
       "      <td>1.779160</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>991.214515</td>\n",
       "      <td>0.269697</td>\n",
       "      <td>3722.447510</td>\n",
       "      <td>1.012831</td>\n",
       "      <td>153671.386680</td>\n",
       "      <td>41.812059</td>\n",
       "      <td>28431.421590</td>\n",
       "      <td>7.735834</td>\n",
       "      <td>39470.886995</td>\n",
       "      <td>10.739534</td>\n",
       "      <td>74885.956375</td>\n",
       "      <td>20.375531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.673405</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889580</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>30958.051185</td>\n",
       "      <td>8.423298</td>\n",
       "      <td>4.670295</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>164.127510</td>\n",
       "      <td>0.044657</td>\n",
       "      <td>4.670295</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>19403.518960</td>\n",
       "      <td>5.279454</td>\n",
       "      <td>4497.494085</td>\n",
       "      <td>1.223712</td>\n",
       "      <td>624.485160</td>\n",
       "      <td>0.169915</td>\n",
       "      <td>1242</td>\n",
       "      <td>-42</td>\n",
       "      <td>44.214286</td>\n",
       "      <td>82.785714</td>\n",
       "      <td>2.392857</td>\n",
       "      <td>39.321429</td>\n",
       "      <td>54.157143</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>35.771429</td>\n",
       "      <td>60.785714</td>\n",
       "      <td>0.095714</td>\n",
       "      <td>45.506897</td>\n",
       "      <td>78.189655</td>\n",
       "      <td>2.915517</td>\n",
       "      <td>38.932759</td>\n",
       "      <td>55.896552</td>\n",
       "      <td>95.448276</td>\n",
       "      <td>35.725862</td>\n",
       "      <td>55.810345</td>\n",
       "      <td>0.130172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>189.035750</td>\n",
       "      <td>0.040080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15482.472715</td>\n",
       "      <td>3.282650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>194.595625</td>\n",
       "      <td>0.041259</td>\n",
       "      <td>195088.007530</td>\n",
       "      <td>41.363269</td>\n",
       "      <td>0.444790</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.222395</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5644.829890</td>\n",
       "      <td>1.196837</td>\n",
       "      <td>121.427670</td>\n",
       "      <td>0.025746</td>\n",
       "      <td>3192.480225</td>\n",
       "      <td>0.676881</td>\n",
       "      <td>0.667185</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>247783.390805</td>\n",
       "      <td>52.535935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2650.503610</td>\n",
       "      <td>0.561969</td>\n",
       "      <td>1297.452430</td>\n",
       "      <td>0.275091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3556</td>\n",
       "      <td>1442</td>\n",
       "      <td>29.657143</td>\n",
       "      <td>76.514286</td>\n",
       "      <td>3.228571</td>\n",
       "      <td>21.328571</td>\n",
       "      <td>34.428571</td>\n",
       "      <td>91.857143</td>\n",
       "      <td>22.857143</td>\n",
       "      <td>55.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.789655</td>\n",
       "      <td>68.162069</td>\n",
       "      <td>4.968966</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>39.344828</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>22.758621</td>\n",
       "      <td>46.344828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1326.808570</td>\n",
       "      <td>0.414290</td>\n",
       "      <td>16.679625</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>1873.010690</td>\n",
       "      <td>0.584840</td>\n",
       "      <td>242.632945</td>\n",
       "      <td>0.075761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17190.911105</td>\n",
       "      <td>5.367789</td>\n",
       "      <td>114386.866695</td>\n",
       "      <td>35.716810</td>\n",
       "      <td>168.130620</td>\n",
       "      <td>0.052498</td>\n",
       "      <td>12.009330</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>120.093300</td>\n",
       "      <td>0.037499</td>\n",
       "      <td>2587.343430</td>\n",
       "      <td>0.807887</td>\n",
       "      <td>112912.610240</td>\n",
       "      <td>35.256480</td>\n",
       "      <td>440.119705</td>\n",
       "      <td>0.137425</td>\n",
       "      <td>8263.975805</td>\n",
       "      <td>2.580391</td>\n",
       "      <td>1727.119570</td>\n",
       "      <td>0.539286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.334370</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111975</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>52457.865415</td>\n",
       "      <td>16.379744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.779160</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>122.094855</td>\n",
       "      <td>0.038124</td>\n",
       "      <td>5822.745890</td>\n",
       "      <td>1.818128</td>\n",
       "      <td>105.860020</td>\n",
       "      <td>0.033054</td>\n",
       "      <td>479.483620</td>\n",
       "      <td>0.149717</td>\n",
       "      <td>3121</td>\n",
       "      <td>43</td>\n",
       "      <td>34.114286</td>\n",
       "      <td>83.571429</td>\n",
       "      <td>3.157143</td>\n",
       "      <td>29.585714</td>\n",
       "      <td>40.071429</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>27.757143</td>\n",
       "      <td>66.571429</td>\n",
       "      <td>0.141429</td>\n",
       "      <td>34.289655</td>\n",
       "      <td>76.724138</td>\n",
       "      <td>3.606897</td>\n",
       "      <td>27.410345</td>\n",
       "      <td>41.200000</td>\n",
       "      <td>93.172414</td>\n",
       "      <td>27.768966</td>\n",
       "      <td>58.310345</td>\n",
       "      <td>0.155517</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3777.156680</td>\n",
       "      <td>0.374865</td>\n",
       "      <td>46196.556585</td>\n",
       "      <td>4.584787</td>\n",
       "      <td>1869.452370</td>\n",
       "      <td>0.185534</td>\n",
       "      <td>2023.349710</td>\n",
       "      <td>0.200808</td>\n",
       "      <td>9.118195</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>33181.556395</td>\n",
       "      <td>3.293111</td>\n",
       "      <td>408193.790775</td>\n",
       "      <td>40.511281</td>\n",
       "      <td>56434.510410</td>\n",
       "      <td>5.600855</td>\n",
       "      <td>10563.317710</td>\n",
       "      <td>1.048359</td>\n",
       "      <td>2628.041715</td>\n",
       "      <td>0.260821</td>\n",
       "      <td>247.525635</td>\n",
       "      <td>0.024566</td>\n",
       "      <td>170758.216925</td>\n",
       "      <td>16.946936</td>\n",
       "      <td>4421.657390</td>\n",
       "      <td>0.438828</td>\n",
       "      <td>25520.048645</td>\n",
       "      <td>2.532743</td>\n",
       "      <td>165.684275</td>\n",
       "      <td>0.016443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>790.391830</td>\n",
       "      <td>0.078443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105624.281300</td>\n",
       "      <td>10.482705</td>\n",
       "      <td>55372.129495</td>\n",
       "      <td>5.495419</td>\n",
       "      <td>94.295480</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>469.475845</td>\n",
       "      <td>0.046593</td>\n",
       "      <td>42057.340845</td>\n",
       "      <td>4.173990</td>\n",
       "      <td>21360.372565</td>\n",
       "      <td>2.119915</td>\n",
       "      <td>11589.893030</td>\n",
       "      <td>1.150241</td>\n",
       "      <td>4257.085090</td>\n",
       "      <td>0.422495</td>\n",
       "      <td>2192</td>\n",
       "      <td>-1</td>\n",
       "      <td>40.985714</td>\n",
       "      <td>81.285714</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>35.557143</td>\n",
       "      <td>50.114286</td>\n",
       "      <td>91.285714</td>\n",
       "      <td>32.171429</td>\n",
       "      <td>62.857143</td>\n",
       "      <td>0.117143</td>\n",
       "      <td>42.389655</td>\n",
       "      <td>77.448276</td>\n",
       "      <td>3.848276</td>\n",
       "      <td>35.586207</td>\n",
       "      <td>52.455172</td>\n",
       "      <td>88.965517</td>\n",
       "      <td>33.365517</td>\n",
       "      <td>58.862069</td>\n",
       "      <td>0.175517</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31.802485</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>28.466560</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>218.391890</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.889580</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34882.878145</td>\n",
       "      <td>5.495994</td>\n",
       "      <td>255438.004310</td>\n",
       "      <td>40.245698</td>\n",
       "      <td>28.688955</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>12.231725</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>2.223950</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>522.183460</td>\n",
       "      <td>0.082273</td>\n",
       "      <td>207502.763615</td>\n",
       "      <td>32.693230</td>\n",
       "      <td>465.027945</td>\n",
       "      <td>0.073268</td>\n",
       "      <td>12257.745215</td>\n",
       "      <td>1.931277</td>\n",
       "      <td>3351.270255</td>\n",
       "      <td>0.528012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889580</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106091.088405</td>\n",
       "      <td>16.715249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667185</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>425.664030</td>\n",
       "      <td>0.067066</td>\n",
       "      <td>13178.682910</td>\n",
       "      <td>2.076376</td>\n",
       "      <td>245.079290</td>\n",
       "      <td>0.038614</td>\n",
       "      <td>11.786935</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>3522</td>\n",
       "      <td>787</td>\n",
       "      <td>41.928571</td>\n",
       "      <td>93.014286</td>\n",
       "      <td>5.657143</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>50.142857</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.571429</td>\n",
       "      <td>74.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.931034</td>\n",
       "      <td>87.017241</td>\n",
       "      <td>6.268966</td>\n",
       "      <td>37.196552</td>\n",
       "      <td>52.827586</td>\n",
       "      <td>97.551724</td>\n",
       "      <td>34.344828</td>\n",
       "      <td>61.275862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fire_started  Alfalfa & Hay_acres  Alfalfa & Hay_percentage  Almonds_acres  \\\n",
       "0           0.0          1102.856805                  0.300074       4.225505   \n",
       "1           0.0           189.035750                  0.040080       0.000000   \n",
       "2           0.0          1326.808570                  0.414290      16.679625   \n",
       "3           0.0          3777.156680                  0.374865   46196.556585   \n",
       "4           0.0            31.802485                  0.005011      28.466560   \n",
       "\n",
       "   Almonds_percentage  Barren_acres  Barren_percentage   Corn_acres  \\\n",
       "0            0.001150    194.595625           0.052947     4.670295   \n",
       "1            0.000000  15482.472715           3.282650     0.000000   \n",
       "2            0.005208   1873.010690           0.584840   242.632945   \n",
       "3            4.584787   1869.452370           0.185534  2023.349710   \n",
       "4            0.004485    218.391890           0.034409     0.889580   \n",
       "\n",
       "   Corn_percentage  Cotton_acres  Cotton_percentage  Deciduous Forest_acres  \\\n",
       "0         0.001271      0.000000           0.000000                5.337480   \n",
       "1         0.000000      0.000000           0.000000              194.595625   \n",
       "2         0.075761      0.000000           0.000000            17190.911105   \n",
       "3         0.200808      9.118195           0.000905            33181.556395   \n",
       "4         0.000140      0.000000           0.000000            34882.878145   \n",
       "\n",
       "   Deciduous Forest_percentage  Evergreen Forest_acres  \\\n",
       "0                     0.001452             7838.756565   \n",
       "1                     0.041259           195088.007530   \n",
       "2                     5.367789           114386.866695   \n",
       "3                     3.293111           408193.790775   \n",
       "4                     5.495994           255438.004310   \n",
       "\n",
       "   Evergreen Forest_percentage  Fallow_acres  Fallow_percentage  \\\n",
       "0                     2.132827   1536.749450           0.418130   \n",
       "1                    41.363269      0.444790           0.000094   \n",
       "2                    35.716810    168.130620           0.052498   \n",
       "3                    40.511281  56434.510410           5.600855   \n",
       "4                    40.245698     28.688955           0.004520   \n",
       "\n",
       "   Fruit Trees_acres  Fruit Trees_percentage  Grain Crops_acres  \\\n",
       "0           1.779160                0.000484         991.214515   \n",
       "1           0.222395                0.000047           0.000000   \n",
       "2          12.009330                0.003750         120.093300   \n",
       "3       10563.317710                1.048359        2628.041715   \n",
       "4          12.231725                0.001927           2.223950   \n",
       "\n",
       "   Grain Crops_percentage  Grapes_acres  Grapes_percentage  Grassland_acres  \\\n",
       "0                0.269697   3722.447510           1.012831    153671.386680   \n",
       "1                0.000000      0.000000           0.000000      5644.829890   \n",
       "2                0.037499   2587.343430           0.807887    112912.610240   \n",
       "3                0.260821    247.525635           0.024566    170758.216925   \n",
       "4                0.000350    522.183460           0.082273    207502.763615   \n",
       "\n",
       "   Grassland_percentage  High Intensity Developed_acres  \\\n",
       "0             41.812059                    28431.421590   \n",
       "1              1.196837                      121.427670   \n",
       "2             35.256480                      440.119705   \n",
       "3             16.946936                     4421.657390   \n",
       "4             32.693230                      465.027945   \n",
       "\n",
       "   High Intensity Developed_percentage  Low Intensity Developed_acres  \\\n",
       "0                             7.735834                   39470.886995   \n",
       "1                             0.025746                    3192.480225   \n",
       "2                             0.137425                    8263.975805   \n",
       "3                             0.438828                   25520.048645   \n",
       "4                             0.073268                   12257.745215   \n",
       "\n",
       "   Low Intensity Developed_percentage  Mixed Forest_acres  \\\n",
       "0                           10.739534        74885.956375   \n",
       "1                            0.676881            0.667185   \n",
       "2                            2.580391         1727.119570   \n",
       "3                            2.532743          165.684275   \n",
       "4                            1.931277         3351.270255   \n",
       "\n",
       "   Mixed Forest_percentage  Other Ocean/Mexico_acres  \\\n",
       "0                20.375531                       0.0   \n",
       "1                 0.000141                       0.0   \n",
       "2                 0.539286                       0.0   \n",
       "3                 0.016443                       0.0   \n",
       "4                 0.528012                       0.0   \n",
       "\n",
       "   Other Ocean/Mexico_percentage  Other Tree Crops_acres  \\\n",
       "0                            0.0                8.673405   \n",
       "1                            0.0                0.000000   \n",
       "2                            0.0                1.334370   \n",
       "3                            0.0              790.391830   \n",
       "4                            0.0                0.889580   \n",
       "\n",
       "   Other Tree Crops_percentage  Other_acres  Other_percentage     Rice_acres  \\\n",
       "0                     0.002360          0.0               0.0       0.889580   \n",
       "1                     0.000000          0.0               0.0       0.000000   \n",
       "2                     0.000417          0.0               0.0       1.111975   \n",
       "3                     0.078443          0.0               0.0  105624.281300   \n",
       "4                     0.000140          0.0               0.0       0.000000   \n",
       "\n",
       "   Rice_percentage  Shrubland_acres  Shrubland_percentage  Tomatoes_acres  \\\n",
       "0         0.000242     30958.051185              8.423298        4.670295   \n",
       "1         0.000000    247783.390805             52.535935        0.000000   \n",
       "2         0.000347     52457.865415             16.379744        0.000000   \n",
       "3        10.482705     55372.129495              5.495419       94.295480   \n",
       "4         0.000000    106091.088405             16.715249        0.000000   \n",
       "\n",
       "   Tomatoes_percentage  Vegs & Fruits_acres  Vegs & Fruits_percentage  \\\n",
       "0             0.001271           164.127510                  0.044657   \n",
       "1             0.000000             0.000000                  0.000000   \n",
       "2             0.000000             1.779160                  0.000556   \n",
       "3             0.009358           469.475845                  0.046593   \n",
       "4             0.000000             0.667185                  0.000105   \n",
       "\n",
       "   Walnuts_acres  Walnuts_percentage   Water_acres  Water_percentage  \\\n",
       "0       4.670295            0.001271  19403.518960          5.279454   \n",
       "1       0.000000            0.000000   2650.503610          0.561969   \n",
       "2     122.094855            0.038124   5822.745890          1.818128   \n",
       "3   42057.340845            4.173990  21360.372565          2.119915   \n",
       "4     425.664030            0.067066  13178.682910          2.076376   \n",
       "\n",
       "   Wetlands_acres  Wetlands_percentage  Winter Wheat_acres  \\\n",
       "0     4497.494085             1.223712          624.485160   \n",
       "1     1297.452430             0.275091            0.000000   \n",
       "2      105.860020             0.033054          479.483620   \n",
       "3    11589.893030             1.150241         4257.085090   \n",
       "4      245.079290             0.038614           11.786935   \n",
       "\n",
       "   Winter Wheat_percentage  max_elevation  min_elevation  \\\n",
       "0                 0.169915           1242            -42   \n",
       "1                 0.000000           3556           1442   \n",
       "2                 0.149717           3121             43   \n",
       "3                 0.422495           2192             -1   \n",
       "4                 0.001857           3522            787   \n",
       "\n",
       "   Avg Air Temp (F)_Weekly  Avg Rel Hum (%)_Weekly  \\\n",
       "0                44.214286               82.785714   \n",
       "1                29.657143               76.514286   \n",
       "2                34.114286               83.571429   \n",
       "3                40.985714               81.285714   \n",
       "4                41.928571               93.014286   \n",
       "\n",
       "   Avg Wind Speed (mph)_Weekly  Dew Point (F)_Weekly  Max Air Temp (F)_Weekly  \\\n",
       "0                     2.392857             39.321429                54.157143   \n",
       "1                     3.228571             21.328571                34.428571   \n",
       "2                     3.157143             29.585714                40.071429   \n",
       "3                     3.142857             35.557143                50.114286   \n",
       "4                     5.657143             39.000000                50.142857   \n",
       "\n",
       "   Max Rel Hum (%)_Weekly  Min Air Temp (F)_Weekly  Min Rel Hum (%)_Weekly  \\\n",
       "0               96.500000                35.771429               60.785714   \n",
       "1               91.857143                22.857143               55.428571   \n",
       "2               96.000000                27.757143               66.571429   \n",
       "3               91.285714                32.171429               62.857143   \n",
       "4              100.000000                35.571429               74.142857   \n",
       "\n",
       "   Precip (in)_Weekly  Avg Air Temp (F)_month  Avg Rel Hum (%)_month  \\\n",
       "0            0.095714               45.506897              78.189655   \n",
       "1            0.000000               30.789655              68.162069   \n",
       "2            0.141429               34.289655              76.724138   \n",
       "3            0.117143               42.389655              77.448276   \n",
       "4            0.000000               42.931034              87.017241   \n",
       "\n",
       "   Avg Wind Speed (mph)_month  Dew Point (F)_month  Max Air Temp (F)_month  \\\n",
       "0                    2.915517            38.932759               55.896552   \n",
       "1                    4.968966            19.600000               39.344828   \n",
       "2                    3.606897            27.410345               41.200000   \n",
       "3                    3.848276            35.586207               52.455172   \n",
       "4                    6.268966            37.196552               52.827586   \n",
       "\n",
       "   Max Rel Hum (%)_month  Min Air Temp (F)_month  Min Rel Hum (%)_month  \\\n",
       "0              95.448276               35.725862              55.810345   \n",
       "1              86.000000               22.758621              46.344828   \n",
       "2              93.172414               27.768966              58.310345   \n",
       "3              88.965517               33.365517              58.862069   \n",
       "4              97.551724               34.344828              61.275862   \n",
       "\n",
       "   Precip (in)_month  Alpine  Amador  Butte  Calaveras  Colusa  Contra Costa  \\\n",
       "0           0.130172       0       0      0          0       0             0   \n",
       "1           0.000000       1       0      0          0       0             0   \n",
       "2           0.155517       0       1      0          0       0             0   \n",
       "3           0.175517       0       0      1          0       0             0   \n",
       "4           0.000000       0       0      0          1       0             0   \n",
       "\n",
       "   Del Norte  El Dorado  Fresno  Glenn  Humboldt  Imperial  Inyo  Kern  Kings  \\\n",
       "0          0          0       0      0         0         0     0     0      0   \n",
       "1          0          0       0      0         0         0     0     0      0   \n",
       "2          0          0       0      0         0         0     0     0      0   \n",
       "3          0          0       0      0         0         0     0     0      0   \n",
       "4          0          0       0      0         0         0     0     0      0   \n",
       "\n",
       "   Lake  Lassen  Los Angeles  Madera  Marin  Mariposa  Mendocino  Merced  \\\n",
       "0     0       0            0       0      0         0          0       0   \n",
       "1     0       0            0       0      0         0          0       0   \n",
       "2     0       0            0       0      0         0          0       0   \n",
       "3     0       0            0       0      0         0          0       0   \n",
       "4     0       0            0       0      0         0          0       0   \n",
       "\n",
       "   Modoc  Mono  Monterey  Napa  Nevada  Orange  Placer  Plumas  Riverside  \\\n",
       "0      0     0         0     0       0       0       0       0          0   \n",
       "1      0     0         0     0       0       0       0       0          0   \n",
       "2      0     0         0     0       0       0       0       0          0   \n",
       "3      0     0         0     0       0       0       0       0          0   \n",
       "4      0     0         0     0       0       0       0       0          0   \n",
       "\n",
       "   Sacramento  San Benito  San Bernardino  San Diego  San Francisco  \\\n",
       "0           0           0               0          0              0   \n",
       "1           0           0               0          0              0   \n",
       "2           0           0               0          0              0   \n",
       "3           0           0               0          0              0   \n",
       "4           0           0               0          0              0   \n",
       "\n",
       "   San Joaquin  San Luis Obispo  San Mateo  Santa Barbara  Santa Clara  \\\n",
       "0            0                0          0              0            0   \n",
       "1            0                0          0              0            0   \n",
       "2            0                0          0              0            0   \n",
       "3            0                0          0              0            0   \n",
       "4            0                0          0              0            0   \n",
       "\n",
       "   Santa Cruz  Shasta  Sierra  Siskiyou  Solano  Sonoma  Stanislaus  Sutter  \\\n",
       "0           0       0       0         0       0       0           0       0   \n",
       "1           0       0       0         0       0       0           0       0   \n",
       "2           0       0       0         0       0       0           0       0   \n",
       "3           0       0       0         0       0       0           0       0   \n",
       "4           0       0       0         0       0       0           0       0   \n",
       "\n",
       "   Tehama  Trinity  Tulare  Tuolumne  Ventura  Yolo  Yuba  2  3  4  5  6  7  \\\n",
       "0       0        0       0         0        0     0     0  0  0  0  0  0  0   \n",
       "1       0        0       0         0        0     0     0  0  0  0  0  0  0   \n",
       "2       0        0       0         0        0     0     0  0  0  0  0  0  0   \n",
       "3       0        0       0         0        0     0     0  0  0  0  0  0  0   \n",
       "4       0        0       0         0        0     0     0  0  0  0  0  0  0   \n",
       "\n",
       "   8  9  10  11  12  \n",
       "0  0  0   0   0   0  \n",
       "1  0  0   0   0   0  \n",
       "2  0  0   0   0   0  \n",
       "3  0  0   0   0   0  \n",
       "4  0  0   0   0   0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling Minority Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a high class imbalance in the target variable. As seen in the EDA, the grand majority of the target variable are instances of no wildfire. In this case, we use upsampling the instances of wildfire to resolve the class imbalance issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the target variable by class into two dataframes\n",
    "no_fire = df2[df2.fire_started == 0] # 0 = No Wildfire\n",
    "fire = df2[df2.fire_started == 1] # 1 = Wildfire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the minority class (wildfire)\n",
    "fire_resample = resample(fire,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=no_fire.shape[0], # match number in majority class\n",
    "                          random_state=42) # reproducible result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe combining the target classes\n",
    "resampled_df = pd.concat([no_fire, fire_resample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    17061\n",
       "0.0    17061\n",
       "Name: fire_started, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double-check the different target classes\n",
    "resampled_df.fire_started.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to split our resampled data into a training dataset and a test dataset. We should do the same for the original class imbalance to test that models have a similar metric when predicting from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split resampled dataset into target variable and features\n",
    "y = resampled_df.fire_started\n",
    "X = resampled_df.drop(columns = ['fire_started'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split original dataset into target variable and features\n",
    "y2 = df2.fire_started\n",
    "X2 = df2.drop(columns = ['fire_started'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create a training dataset and test dataset\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,  y2, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create a training dataset and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,  y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first type of model we tried was logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our base model, we run the resampled training data through a logistic regression model with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malcolmkatzenbach/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a logistic regression model\n",
    "logreg = LogisticRegression(random_state = 0) # random state for consistant results\n",
    "# Train model on resampled training data\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict the target variable on the training dataset\n",
    "y_hat_train = logreg.predict(X_train)\n",
    "# Use the model to predict the target variable on the test dataset\n",
    "y_hat_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6618738558828424 0.6610761705101327\n",
      "0.6030245008010628 0.6020396202086508\n",
      "0.7786217697729052 0.7716150081566069\n"
     ]
    }
   ],
   "source": [
    "# Import metrics used\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix\n",
    "# Print the f1 score metric on both the training and test predictions to check for overfitting\n",
    "print(f1_score(y_train, y_hat_train), f1_score(y_test, y_hat_test))\n",
    "# Print the accuracy score metric on both the training and test predictions to check for overfitting\n",
    "print(accuracy_score(y_train, y_hat_train), accuracy_score(y_test, y_hat_test))\n",
    "# Print the recall score metric on both the training and test predictions to check for overfitting\n",
    "print(recall_score(y_train, y_hat_train), recall_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of our metrics show that the recall and f1 score are both higher than the accuracy score, which is unusual. We use a confusion matrix to find the false positive and false negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1825, 2415],\n",
       "       [ 980, 3311]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, there is a high number of false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Scaled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our first iteration we want to check how normalizing the features will change our score. Due to the resampled data already having class balance, we don't have to change anything to do with `class_weight`. To normalize our data, we will use a Standard Scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insantiate the StandardScaler()\n",
    "ss = StandardScaler()\n",
    "# Fit the feature training data\n",
    "ss.fit(X_train)\n",
    "ss.fit(X_train2)\n",
    "\n",
    "# Transform both the training and test features\n",
    "X_train_scaled = ss.transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "X_train_scaled2 = ss.transform(X_train2)\n",
    "X_test_scaled2 = ss.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a new logistic regression model\n",
    "logreg1 = LogisticRegression(solver = 'liblinear')\n",
    "# Fit the data to the new scaled data\n",
    "logreg1.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict target variable on the training dataset\n",
    "y_hat_train1 = logreg1.predict(X_train_scaled)\n",
    "# Use model to predict target variable on the test dataset\n",
    "y_hat_test1 = logreg1.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.810233592880979 0.8075346260387812\n",
      "0.8000078152475479 0.7963896377915837\n",
      "0.8555990602975725 0.8492192962013516\n"
     ]
    }
   ],
   "source": [
    "# Print the f1 score metric on both the training and test predictions to check for overfitting\n",
    "print(f1_score(y_train, y_hat_train1), f1_score(y_test, y_hat_test1))\n",
    "# Print the accuracy score metric on both the training and test predictions to check for overfitting\n",
    "print(accuracy_score(y_train, y_hat_train1), accuracy_score(y_test, y_hat_test1))\n",
    "# Print the recall score metric on both the training and test predictions to check for overfitting\n",
    "print(recall_score(y_train, y_hat_train1), recall_score(y_test, y_hat_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from our metrics show an increase in score across the board. However, the f1 and recall score are still slightly better than the accuracy score. We check the confusion matrix next to check the value counts for false positive and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3150, 1090],\n",
       "       [ 647, 3644]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows as in the previous model, the most error occurs from the model predicting false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor (KNN) Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second type of model we used was K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our base knn model, we chose k as 3. Due to how knn models function, the number of nearest neighbors should always be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a knn model using 3 nearest neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit knn model using the scaled data from the previous scaled logistic model\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target variable for both the train and test datasets.\n",
    "knn_train = knn.predict(X_train_scaled)\n",
    "knn_test = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695911316958354 0.9448420125509193\n",
      "0.9686999335703959 0.9412730043371235\n",
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the f1 score metric on both the training and test predictions to check for overfitting\n",
    "print(f1_score(y_train, knn_train), f1_score(y_test, knn_test))\n",
    "# Print the sccuracy score metric on both the training and test predictions to check for overfitting\n",
    "print(accuracy_score(y_train, knn_train), accuracy_score(y_test, knn_test))\n",
    "# Print the recall score metric on both the training and test predictions to check for overfitting\n",
    "print(recall_score(y_train, knn_train), recall_score(y_test, knn_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that this model is strong in reducing false negatives. The errors we will see in the confusion matrix will be false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3739,  501],\n",
       "       [   0, 4291]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, knn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Number of Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tune the number (k) nearest neighbors, want to find the value of k that will return the max value for a given metric. In our base model, it was able to predict the target variable with no false negatives. Thus to gain the best model the metric we used to tune our model was the f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to find the max f1 score and return the score along with the k value\n",
    "def max_value(l):\n",
    "    max_val = max(l)\n",
    "    max_idx = l.index(max_val)\n",
    "    return max_idx, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9685137117706805\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list for f1 scores\n",
    "k_scores = []\n",
    "# Choose a range of k values to test\n",
    "k_range = list(range(1, 21))\n",
    "# Iterate through the different k values\n",
    "for k in k_range:\n",
    "    # Instantiate new knn model with k nearest neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    # Fit knn model on scaled training data\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    # Use model to predict target variable on testing set\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "    # Find the f1 score\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    # Append f1 score to list of f1 scorees\n",
    "    k_scores.append(f1)\n",
    "\n",
    "# Find max f1 score\n",
    "idx, val = max_value(k_scores)\n",
    "# Print max f1 score and it corresponding k value\n",
    "print(idx + 1, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best k value is 1 with an f1 score of 96%. We rerun the model using k=1 and check the recall and accuracy metrics of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9685137117706805\n",
      "1.0 0.9672957449302544\n",
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "knn_train1 = knn.predict(X_train_scaled)\n",
    "print(f1_score(y_train, knn_train1), f1_score(y_test, y_pred))\n",
    "print(accuracy_score(y_train, knn_train1), accuracy_score(y_test, y_pred))\n",
    "print(recall_score(y_train, knn_train1), recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has a slightly higher f1 and accuracy score than the base model and recall is still 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3961,  279],\n",
       "       [   0, 4291]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error from this model is predicting false positives.\n",
    "\n",
    "Next we want to check how the model does on the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8863134657836645 0.888208269525268\n",
      "0.9848696290855674 0.9839171623705663\n",
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "knn_pred_test = knn.predict(X_test_scaled2)\n",
    "knn_pred_train = knn.predict(X_train_scaled2)\n",
    "print(f1_score(y_train2, knn_pred_train), f1_score(y_test2, knn_pred_test))\n",
    "print(accuracy_score(y_train2, knn_pred_train), accuracy_score(y_test2, knn_pred_test))\n",
    "print(recall_score(y_train2, knn_pred_train), recall_score(y_test2, knn_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and test accuracy, and training f1 score did slightly worse than with our resampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4176,   73],\n",
       "       [   0,  290]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test2, knn_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', random_state=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state = 0, class_weight = 'balanced')\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9688417249943553\n",
      "1.0 0.9676474035869183\n",
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "dt_train = dt.predict(X_train)\n",
    "dt_test = dt.predict(X_test)\n",
    "\n",
    "print(f1_score(y_train, dt_train), f1_score(y_test, dt_test))\n",
    "print(accuracy_score(y_train, dt_train), accuracy_score(y_test, dt_test))\n",
    "print(recall_score(y_train, dt_train), recall_score(y_test, dt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth' : range(1, 21, 1), 'max_features' : range(55, 75, 1), 'min_samples_split' : range(15, 25, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4000 candidates, totalling 40000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2418 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3168 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done 4018 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4968 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6018 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7168 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8418 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9768 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 11218 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 12768 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 14418 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 16168 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 18018 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 19968 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 22018 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 24168 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 26418 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 28768 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 31218 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 33768 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 36418 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=-1)]: Done 39168 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done 40000 out of 40000 | elapsed: 21.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                              random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': range(1, 21),\n",
       "                         'max_features': range(55, 75),\n",
       "                         'min_samples_split': range(15, 25)},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtg = DecisionTreeClassifier(random_state = 0, class_weight = 'balanced')\n",
    "grid_model = GridSearchCV(dtg, parameters, cv = 10, scoring = 'f1', verbose = 1, n_jobs = -1)\n",
    "\n",
    "grid_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9403985380964534\n",
      "{'max_depth': 20, 'max_features': 55, 'min_samples_split': 15}\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=20, max_features=55,\n",
      "                       min_samples_split=15, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "print(grid_model.best_score_)\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.938507070042749 0.9342398312038448 0.9976695408995572\n",
      "0.9569065746540149 0.9551014028369349 0.998981989036805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3689,  551],\n",
       "       [  10, 4281]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid_model.best_estimator_.predict(X_test)\n",
    "print(f1_score(y_test, y_pred), accuracy_score(y_test, y_pred), recall_score(y_test, y_pred))\n",
    "dt_train2 = grid_model.best_estimator_.predict(X_train)\n",
    "print(f1_score(y_train, dt_train2), accuracy_score(y_train, dt_train2), recall_score(y_train, dt_train2))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5848506919155134 0.5806451612903225\n",
      "0.9162688211531399 0.9083498567966513\n",
      "1.0 0.993103448275862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3835,  414],\n",
       "       [   2,  288]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtg_pred_test = grid_model.best_estimator_.predict(X_test2)\n",
    "dtg_pred_train = grid_model.best_estimator_.predict(X_train2)\n",
    "print(f1_score(y_train2, dtg_pred_train), f1_score(y_test2, dtg_pred_test))\n",
    "print(accuracy_score(y_train2, dtg_pred_train), accuracy_score(y_test2, dtg_pred_test))\n",
    "print(recall_score(y_train2, dtg_pred_train), recall_score(y_test2, dtg_pred_test))\n",
    "confusion_matrix(y_test2, dtg_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters2 = {'max_depth' : range(1, 15, 1), 'max_features' : range(45, 65, 1), 'min_samples_split' : range(10, 20, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2800 candidates, totalling 28000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 676 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1376 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2276 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3376 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4676 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6176 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 7876 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=-1)]: Done 9776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 11876 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14176 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 16676 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 19376 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 22276 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 25376 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 28000 out of 28000 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=0,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': range(1, 15),\n",
       "                         'max_features': range(45, 65),\n",
       "                         'min_samples_split': range(10, 20)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtg2 = DecisionTreeClassifier(random_state = 0, class_weight = 'balanced')\n",
    "dtg2_model = GridSearchCV(dtg2, parameters2, cv = 10, scoring = 'f1', verbose = 1, n_jobs = -1)\n",
    "\n",
    "dtg2_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.284097496138901\n",
      "{'max_depth': 14, 'max_features': 59, 'min_samples_split': 14}\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=14,\n",
      "                       max_features=59, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=14,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=0, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(dtg2_model.best_score_)\n",
    "print(dtg2_model.best_params_)\n",
    "print(dtg2_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2611731843575419 0.7669090107953294 0.6448275862068965\n",
      "0.5128040973111395 0.8882115313991921 0.9975093399750934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3294,  955],\n",
       "       [ 103,  187]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = dtg2_model.best_estimator_.predict(X_test)\n",
    "print(f1_score(y_test, y_pred2), accuracy_score(y_test, y_pred2), recall_score(y_test, y_pred2))\n",
    "dtg_train2 = grid_model.best_estimator_.predict(X_train)\n",
    "print(f1_score(y_train, dtg_train2), accuracy_score(y_train, dtg_train2), recall_score(y_train, dtg_train2))\n",
    "confusion_matrix(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters3 = {'max_depth' : range(1, 10, 1), 'max_features' : range(35, 65, 1), 'min_samples_split' : range(14, 30, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4320 candidates, totalling 43200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 804 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1504 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2404 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3504 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4804 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 6304 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=-1)]: Done 8004 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done 9904 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=-1)]: Done 12004 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14304 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 16804 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19504 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 22404 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 25504 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 28804 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 32304 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 36004 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 39904 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 43200 out of 43200 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=0,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': range(1, 10),\n",
       "                         'max_features': range(35, 65),\n",
       "                         'min_samples_split': range(14, 30)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtg3 = DecisionTreeClassifier(random_state = 0, class_weight = 'balanced')\n",
    "dtg3_model = GridSearchCV(dtg3, parameters3, cv = 10, scoring = 'f1', verbose = 1, n_jobs = -1)\n",
    "\n",
    "dtg3_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2675162538246359\n",
      "{'max_depth': 9, 'max_features': 47, 'min_samples_split': 25}\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=9,\n",
      "                       max_features=47, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=25,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=0, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(dtg3_model.best_score_)\n",
    "print(dtg3_model.best_params_)\n",
    "print(dtg3_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2469135802469136 0.7177792465300727 0.7241379310344828\n",
      "0.5128040973111395 0.8882115313991921 0.9975093399750934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3048, 1201],\n",
       "       [  80,  210]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3 = dtg3_model.best_estimator_.predict(X_test)\n",
    "print(f1_score(y_test, y_pred3), accuracy_score(y_test, y_pred3), recall_score(y_test, y_pred3))\n",
    "dtg_train3 = grid_model.best_estimator_.predict(X_train)\n",
    "print(f1_score(y_train, dtg_train3), accuracy_score(y_train, dtg_train3), recall_score(y_train, dtg_train3))\n",
    "confusion_matrix(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for Overfitting with 100 iterations\n",
      "Decision Tree Train recall:  0.9114670787680388\n",
      "Decision Tree Test recall:  0.9105734780901449\n"
     ]
    }
   ],
   "source": [
    "n = 100 # of iteration\n",
    "# value intialization\n",
    "train_recall_sum = 0\n",
    "test_recall_sum = 0\n",
    "# f1 is same as recall when using micro as average value\n",
    "\n",
    "for i in range(0, n): \n",
    "    # new split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    #predict on new split\n",
    "    y_tree_train_pred = dtg3_model.best_estimator_.predict(X_train)\n",
    "    y_tree_test_pred = dtg3_model.best_estimator_.predict(X_test)\n",
    "    \n",
    "    #calculate recall score on new prediction\n",
    "    train_recall_sum += recall_score(y_train, y_tree_train_pred)\n",
    "    test_recall_sum += recall_score(y_test, y_tree_test_pred)\n",
    "    #f1\n",
    "    # print(\"Predicted\", i+1, \"times\") #sanity check\n",
    "\n",
    "# output average    \n",
    "print(f\"Check for Overfitting with {n} iterations\")\n",
    "print(\"Decision Tree Train recall: \", train_recall_sum/n)\n",
    "print(\"Decision Tree Test recall: \", test_recall_sum/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for Overfitting with 100 iterations\n",
      "Decision Tree Train accuracy:  0.7462005141388174\n",
      "Decision Tree Test accuracy:  0.7460850407578764\n"
     ]
    }
   ],
   "source": [
    "n = 100 # of iteration\n",
    "# value intialization\n",
    "train_accuracy_sum = 0\n",
    "test_accuracy_sum = 0\n",
    "# f1 is same as recall when using micro as average value\n",
    "\n",
    "for i in range(0, n): \n",
    "    # new split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    #predict on new split\n",
    "    y_tree_train_pred = dtg3_model.best_estimator_.predict(X_train)\n",
    "    y_tree_test_pred = dtg3_model.best_estimator_.predict(X_test)\n",
    "    \n",
    "    #calculate recall score on new prediction\n",
    "    train_accuracy_sum += accuracy_score(y_train, y_tree_train_pred)\n",
    "    test_accuracy_sum += accuracy_score(y_test, y_tree_test_pred)\n",
    "    #f1\n",
    "    # print(\"Predicted\", i+1, \"times\") #sanity check\n",
    "\n",
    "# output average    \n",
    "print(f\"Check for Overfitting with {n} iterations\")\n",
    "print(\"Decision Tree Train accuracy: \", train_accuracy_sum/n)\n",
    "print(\"Decision Tree Test accuracy: \", test_accuracy_sum/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Class Imbalance Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "\u001b[K     |████████████████████████████████| 167 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /Users/malcolmkatzenbach/anaconda3/envs/learn-env/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.5.0)\n",
      "Collecting scikit-learn>=0.23\n",
      "  Downloading scikit_learn-0.23.2-cp36-cp36m-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 4.6 MB/s eta 0:00:01     |█████████████████████████▎      | 5.7 MB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /Users/malcolmkatzenbach/anaconda3/envs/learn-env/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/malcolmkatzenbach/anaconda3/envs/learn-env/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.16.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.21.3\n",
      "    Uninstalling scikit-learn-0.21.3:\n",
      "      Successfully uninstalled scikit-learn-0.21.3\n",
      "Successfully installed imbalanced-learn-0.7.0 imblearn-0.0 scikit-learn-0.23.2 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
